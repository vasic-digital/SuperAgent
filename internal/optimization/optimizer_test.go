package optimization

import (
	"context"
	"encoding/json"
	"fmt"
	"net/http"
	"net/http/httptest"
	"sync"
	"sync/atomic"
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"

	"dev.helix.agent/internal/optimization/outlines"
	"dev.helix.agent/internal/optimization/streaming"
)

func TestDefaultConfig(t *testing.T) {
	config := DefaultConfig()

	assert.True(t, config.Enabled)
	assert.True(t, config.SemanticCache.Enabled)
	assert.Equal(t, 0.85, config.SemanticCache.SimilarityThreshold)
	assert.Equal(t, 10000, config.SemanticCache.MaxEntries)
	assert.Equal(t, 24*time.Hour, config.SemanticCache.TTL)

	assert.True(t, config.StructuredOutput.Enabled)
	assert.True(t, config.StructuredOutput.StrictMode)
	assert.Equal(t, 3, config.StructuredOutput.MaxRetries)

	assert.True(t, config.Streaming.Enabled)
	assert.Equal(t, "word", config.Streaming.BufferType)

	assert.Equal(t, "skip", config.Fallback.OnServiceUnavailable)
}

func TestConfigValidate(t *testing.T) {
	tests := []struct {
		name   string
		modify func(*Config)
		check  func(*testing.T, *Config)
	}{
		{
			name: "fix invalid similarity threshold",
			modify: func(c *Config) {
				c.SemanticCache.SimilarityThreshold = 2.0
			},
			check: func(t *testing.T, c *Config) {
				assert.Equal(t, 0.85, c.SemanticCache.SimilarityThreshold)
			},
		},
		{
			name: "fix negative similarity threshold",
			modify: func(c *Config) {
				c.SemanticCache.SimilarityThreshold = -0.5
			},
			check: func(t *testing.T, c *Config) {
				assert.Equal(t, 0.85, c.SemanticCache.SimilarityThreshold)
			},
		},
		{
			name: "fix zero max entries",
			modify: func(c *Config) {
				c.SemanticCache.MaxEntries = 0
			},
			check: func(t *testing.T, c *Config) {
				assert.Equal(t, 10000, c.SemanticCache.MaxEntries)
			},
		},
		{
			name: "fix zero max retries",
			modify: func(c *Config) {
				c.StructuredOutput.MaxRetries = 0
			},
			check: func(t *testing.T, c *Config) {
				assert.Equal(t, 3, c.StructuredOutput.MaxRetries)
			},
		},
	}

	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			config := DefaultConfig()
			tt.modify(config)
			err := config.Validate()
			require.NoError(t, err)
			tt.check(t, config)
		})
	}
}

func TestNewService(t *testing.T) {
	t.Run("with nil config uses defaults", func(t *testing.T) {
		svc, err := NewService(nil)
		require.NoError(t, err)
		assert.NotNil(t, svc)
		assert.NotNil(t, svc.config)
		assert.True(t, svc.config.Enabled)
	})

	t.Run("with custom config", func(t *testing.T) {
		config := &Config{
			Enabled: true,
			SemanticCache: SemanticCacheConfig{
				Enabled:             true,
				SimilarityThreshold: 0.9,
				MaxEntries:          5000,
				TTL:                 12 * time.Hour,
			},
			Streaming: StreamingConfig{
				Enabled:    true,
				BufferType: "sentence",
			},
		}

		svc, err := NewService(config)
		require.NoError(t, err)
		assert.NotNil(t, svc)
		assert.Equal(t, 0.9, svc.config.SemanticCache.SimilarityThreshold)
	})

	t.Run("initializes semantic cache when enabled", func(t *testing.T) {
		config := DefaultConfig()
		config.SemanticCache.Enabled = true

		svc, err := NewService(config)
		require.NoError(t, err)
		assert.NotNil(t, svc.semanticCache)
	})

	t.Run("does not initialize semantic cache when disabled", func(t *testing.T) {
		config := DefaultConfig()
		config.SemanticCache.Enabled = false

		svc, err := NewService(config)
		require.NoError(t, err)
		assert.Nil(t, svc.semanticCache)
	})

	t.Run("initializes enhanced streamer when enabled", func(t *testing.T) {
		config := DefaultConfig()
		config.Streaming.Enabled = true

		svc, err := NewService(config)
		require.NoError(t, err)
		assert.NotNil(t, svc.enhancedStreamer)
	})
}

func TestServiceOptimizeRequest(t *testing.T) {
	ctx := context.Background()

	t.Run("returns original prompt when no optimizations apply", func(t *testing.T) {
		config := DefaultConfig()
		config.SemanticCache.Enabled = false
		config.LlamaIndex.Enabled = false
		config.LangChain.Enabled = false
		config.SGLang.Enabled = false

		svc, err := NewService(config)
		require.NoError(t, err)

		result, err := svc.OptimizeRequest(ctx, "Hello world", nil)
		require.NoError(t, err)
		assert.Equal(t, "Hello world", result.OriginalPrompt)
		assert.Equal(t, "Hello world", result.OptimizedPrompt)
		assert.False(t, result.CacheHit)
	})

	t.Run("returns cache hit when found", func(t *testing.T) {
		config := DefaultConfig()
		config.SemanticCache.Enabled = true
		// Disable external services
		config.LlamaIndex.Enabled = false
		config.LangChain.Enabled = false
		config.SGLang.Enabled = false

		svc, err := NewService(config)
		require.NoError(t, err)

		// First, add an entry to the cache
		embedding := []float64{1.0, 0.0, 0.0}
		_, err = svc.semanticCache.Set(ctx, "test query", "cached response", embedding, nil)
		require.NoError(t, err)

		// Now request with the same embedding
		result, err := svc.OptimizeRequest(ctx, "test query", embedding)
		require.NoError(t, err)
		assert.True(t, result.CacheHit)
		assert.Equal(t, "cached response", result.CachedResponse)
	})

	t.Run("increments cache miss counter", func(t *testing.T) {
		config := DefaultConfig()
		config.SemanticCache.Enabled = true
		config.LlamaIndex.Enabled = false
		config.LangChain.Enabled = false
		config.SGLang.Enabled = false

		svc, err := NewService(config)
		require.NoError(t, err)

		initialMisses := svc.cacheMisses

		// Request with an embedding that won't match anything
		embedding := []float64{0.5, 0.5, 0.0}
		_, err = svc.OptimizeRequest(ctx, "new query", embedding)
		require.NoError(t, err)

		assert.Equal(t, initialMisses+1, svc.cacheMisses)
	})
}

func TestServiceOptimizeResponse(t *testing.T) {
	ctx := context.Background()

	t.Run("caches response when semantic cache enabled", func(t *testing.T) {
		config := DefaultConfig()
		config.SemanticCache.Enabled = true

		svc, err := NewService(config)
		require.NoError(t, err)

		embedding := []float64{1.0, 0.0, 0.0}
		result, err := svc.OptimizeResponse(ctx, "test response", embedding, "test query", nil)
		require.NoError(t, err)
		assert.True(t, result.Cached)
		assert.Equal(t, "test response", result.Content)
	})

	t.Run("validates structured output when schema provided", func(t *testing.T) {
		config := DefaultConfig()
		config.StructuredOutput.Enabled = true

		svc, err := NewService(config)
		require.NoError(t, err)

		schema := outlines.StringSchema()
		result, err := svc.OptimizeResponse(ctx, `"hello"`, nil, "test", schema)
		require.NoError(t, err)
		assert.NotNil(t, result.ValidationResult)
		assert.True(t, result.ValidationResult.Valid)
	})

	t.Run("does not validate when schema is nil", func(t *testing.T) {
		config := DefaultConfig()
		config.StructuredOutput.Enabled = true

		svc, err := NewService(config)
		require.NoError(t, err)

		result, err := svc.OptimizeResponse(ctx, "plain text", nil, "test", nil)
		require.NoError(t, err)
		assert.Nil(t, result.ValidationResult)
	})
}

func TestServiceStreamEnhanced(t *testing.T) {
	ctx := context.Background()

	t.Run("returns enhanced stream when streaming enabled", func(t *testing.T) {
		config := DefaultConfig()
		config.Streaming.Enabled = true

		svc, err := NewService(config)
		require.NoError(t, err)

		in := make(chan *streaming.StreamChunk, 3)
		in <- &streaming.StreamChunk{Content: "Hello ", Index: 0}
		in <- &streaming.StreamChunk{Content: "world", Index: 1}
		in <- &streaming.StreamChunk{Content: "", Index: 2, Done: true}
		close(in)

		out, getResult := svc.StreamEnhanced(ctx, in, nil)

		// Consume output
		for range out {
		}

		result := getResult()
		assert.NotNil(t, result)
		assert.Contains(t, result.FullContent, "Hello")
	})

	t.Run("returns passthrough when streaming disabled", func(t *testing.T) {
		config := DefaultConfig()
		config.Streaming.Enabled = false

		svc, err := NewService(config)
		require.NoError(t, err)

		in := make(chan *streaming.StreamChunk, 2)
		in <- &streaming.StreamChunk{Content: "Test", Index: 0}
		in <- &streaming.StreamChunk{Content: "", Index: 1, Done: true}
		close(in)

		out, getResult := svc.StreamEnhanced(ctx, in, nil)

		// Consume output
		for range out {
		}

		result := getResult()
		assert.NotNil(t, result)
	})
}

func TestServiceGenerateStructured(t *testing.T) {
	ctx := context.Background()

	t.Run("returns error when structured output disabled", func(t *testing.T) {
		config := DefaultConfig()
		config.StructuredOutput.Enabled = false

		svc, err := NewService(config)
		require.NoError(t, err)

		schema := outlines.StringSchema()
		generator := func(prompt string) (string, error) {
			return `"test"`, nil
		}

		_, err = svc.GenerateStructured(ctx, "test", schema, generator)
		assert.Error(t, err)
		assert.Contains(t, err.Error(), "not enabled")
	})

	t.Run("generates and validates structured output", func(t *testing.T) {
		config := DefaultConfig()
		config.StructuredOutput.Enabled = true

		svc, err := NewService(config)
		require.NoError(t, err)

		schema := outlines.ObjectSchema(map[string]*outlines.JSONSchema{
			"name": outlines.StringSchema(),
			"age":  outlines.IntegerSchema(),
		}, "name", "age")

		generator := func(prompt string) (string, error) {
			return `{"name": "John", "age": 30}`, nil
		}

		result, err := svc.GenerateStructured(ctx, "Generate a person", schema, generator)
		require.NoError(t, err)
		assert.True(t, result.Valid)
		assert.Contains(t, result.Content, "John")
	})

	t.Run("returns validation errors for invalid output", func(t *testing.T) {
		config := DefaultConfig()
		config.StructuredOutput.Enabled = true

		svc, err := NewService(config)
		require.NoError(t, err)

		schema := outlines.ObjectSchema(map[string]*outlines.JSONSchema{
			"name": outlines.StringSchema(),
		}, "name")

		generator := func(prompt string) (string, error) {
			return `{"invalid": "missing name"}`, nil
		}

		result, err := svc.GenerateStructured(ctx, "Generate a person", schema, generator)
		require.NoError(t, err)
		assert.False(t, result.Valid)
		assert.NotEmpty(t, result.Errors)
	})
}

func TestServiceGetCacheStats(t *testing.T) {
	t.Run("returns stats when cache enabled", func(t *testing.T) {
		config := DefaultConfig()
		config.SemanticCache.Enabled = true

		svc, err := NewService(config)
		require.NoError(t, err)

		stats := svc.GetCacheStats()
		assert.True(t, stats["enabled"].(bool))
		assert.Equal(t, int64(0), stats["hits"])
		assert.Equal(t, int64(0), stats["misses"])
	})

	t.Run("returns disabled when cache not enabled", func(t *testing.T) {
		config := DefaultConfig()
		config.SemanticCache.Enabled = false

		svc, err := NewService(config)
		require.NoError(t, err)

		stats := svc.GetCacheStats()
		assert.False(t, stats["enabled"].(bool))
	})
}

func TestServiceGetServiceStatus(t *testing.T) {
	ctx := context.Background()

	t.Run("returns empty map when no services configured", func(t *testing.T) {
		config := DefaultConfig()
		config.SGLang.Enabled = false
		config.LlamaIndex.Enabled = false
		config.LangChain.Enabled = false
		config.Guidance.Enabled = false
		config.LMQL.Enabled = false

		svc, err := NewService(config)
		require.NoError(t, err)

		status := svc.GetServiceStatus(ctx)
		assert.Empty(t, status)
	})
}

func TestServiceIsServiceAvailable(t *testing.T) {
	t.Run("returns true for unknown service", func(t *testing.T) {
		config := DefaultConfig()
		svc, err := NewService(config)
		require.NoError(t, err)

		// Unknown services are assumed available
		assert.True(t, svc.isServiceAvailable("unknown"))
	})

	t.Run("returns false when service marked unavailable", func(t *testing.T) {
		config := DefaultConfig()
		svc, err := NewService(config)
		require.NoError(t, err)

		svc.markServiceUnavailable("test-service")

		assert.False(t, svc.isServiceAvailable("test-service"))
	})
}

func TestIsComplexTask(t *testing.T) {
	tests := []struct {
		prompt   string
		expected bool
	}{
		{"Hello", false},
		{"What is 2+2?", false},
		// Prompts must be > 100 chars for indicator matching
		{"Please implement a function that calculates fibonacci numbers. I need this to be efficient and handle large numbers step by step", true},
		{"Create a new user authentication system with login and registration functionality. This should include password hashing and session management", true},
		{"Build a REST API with CRUD operations for a product catalog. The API should support filtering, pagination, and sorting capabilities", true},
		{string(make([]byte, 600)), true}, // Long prompt
	}

	for _, tt := range tests {
		t.Run(tt.prompt[:min(30, len(tt.prompt))], func(t *testing.T) {
			result := isComplexTask(tt.prompt)
			assert.Equal(t, tt.expected, result)
		})
	}
}

func TestServiceExternalServicesUnavailable(t *testing.T) {
	ctx := context.Background()

	t.Run("DecomposeTask returns error when langchain unavailable", func(t *testing.T) {
		config := DefaultConfig()
		config.LangChain.Enabled = false

		svc, err := NewService(config)
		require.NoError(t, err)

		_, err = svc.DecomposeTask(ctx, "test task")
		assert.Error(t, err)
		assert.Contains(t, err.Error(), "not available")
	})

	t.Run("RunReActAgent returns error when langchain unavailable", func(t *testing.T) {
		config := DefaultConfig()
		config.LangChain.Enabled = false

		svc, err := NewService(config)
		require.NoError(t, err)

		_, err = svc.RunReActAgent(ctx, "test goal", []string{"search"})
		assert.Error(t, err)
		assert.Contains(t, err.Error(), "not available")
	})

	t.Run("QueryDocuments returns error when llamaindex unavailable", func(t *testing.T) {
		config := DefaultConfig()
		config.LlamaIndex.Enabled = false

		svc, err := NewService(config)
		require.NoError(t, err)

		_, err = svc.QueryDocuments(ctx, "test query", nil)
		assert.Error(t, err)
		assert.Contains(t, err.Error(), "not available")
	})

	t.Run("GenerateConstrained returns error when lmql unavailable", func(t *testing.T) {
		config := DefaultConfig()
		config.LMQL.Enabled = false

		svc, err := NewService(config)
		require.NoError(t, err)

		_, err = svc.GenerateConstrained(ctx, "test", nil)
		assert.Error(t, err)
		assert.Contains(t, err.Error(), "not available")
	})

	t.Run("SelectFromOptions returns error when guidance unavailable", func(t *testing.T) {
		config := DefaultConfig()
		config.Guidance.Enabled = false

		svc, err := NewService(config)
		require.NoError(t, err)

		_, err = svc.SelectFromOptions(ctx, "choose", []string{"a", "b"})
		assert.Error(t, err)
		assert.Contains(t, err.Error(), "not available")
	})

	t.Run("CreateSession returns error when sglang unavailable", func(t *testing.T) {
		config := DefaultConfig()
		config.SGLang.Enabled = false

		svc, err := NewService(config)
		require.NoError(t, err)

		err = svc.CreateSession(ctx, "session1", "system prompt")
		assert.Error(t, err)
		assert.Contains(t, err.Error(), "not available")
	})

	t.Run("ContinueSession returns error when sglang unavailable", func(t *testing.T) {
		config := DefaultConfig()
		config.SGLang.Enabled = false

		svc, err := NewService(config)
		require.NoError(t, err)

		_, err = svc.ContinueSession(ctx, "session1", "hello")
		assert.Error(t, err)
		assert.Contains(t, err.Error(), "not available")
	})
}

func TestServiceMarkServiceUnavailable(t *testing.T) {
	config := DefaultConfig()
	svc, err := NewService(config)
	require.NoError(t, err)

	svc.markServiceUnavailable("test-service")

	svc.mu.RLock()
	status := svc.serviceStatus["test-service"]
	until := svc.unavailableUntil["test-service"]
	svc.mu.RUnlock()

	assert.False(t, status)
	assert.True(t, until.After(time.Now()))
}

func TestServiceIsServiceAvailable_RetryAfterTimeout(t *testing.T) {
	config := DefaultConfig()
	config.Fallback.RetryUnavailableAfter = 50 * time.Millisecond

	svc, err := NewService(config)
	require.NoError(t, err)

	svc.markServiceUnavailable("test-service")

	// Immediately should be unavailable
	assert.False(t, svc.isServiceAvailable("test-service"))

	// Wait for retry period
	time.Sleep(60 * time.Millisecond)

	// Should be available again (retry period passed)
	assert.True(t, svc.isServiceAvailable("test-service"))
}

func TestServiceIsServiceAvailable_CachedStatus(t *testing.T) {
	config := DefaultConfig()
	config.Fallback.HealthCheckInterval = 1 * time.Hour // Long interval

	svc, err := NewService(config)
	require.NoError(t, err)

	// Set cached status
	svc.mu.Lock()
	svc.serviceStatus["cached-service"] = true
	svc.lastHealthCheck["cached-service"] = time.Now()
	svc.mu.Unlock()

	// Should return cached status
	assert.True(t, svc.isServiceAvailable("cached-service"))
}

func TestServiceGetCacheStats_WithEntries(t *testing.T) {
	ctx := context.Background()
	config := DefaultConfig()
	config.SemanticCache.Enabled = true

	svc, err := NewService(config)
	require.NoError(t, err)

	// Add some entries
	embedding := []float64{1.0, 0.0, 0.0}
	_, err = svc.semanticCache.Set(ctx, "query1", "response1", embedding, nil)
	require.NoError(t, err)

	stats := svc.GetCacheStats()
	assert.True(t, stats["enabled"].(bool))
	// After adding an entry, stats should reflect it
	if entries, ok := stats["entries"]; ok {
		assert.GreaterOrEqual(t, entries.(int), 1)
	}
}

func TestServiceOptimizeRequest_WithEmbeddingMiss(t *testing.T) {
	ctx := context.Background()

	config := DefaultConfig()
	config.SemanticCache.Enabled = true
	config.LlamaIndex.Enabled = false
	config.LangChain.Enabled = false
	config.SGLang.Enabled = false

	svc, err := NewService(config)
	require.NoError(t, err)

	// Request with an embedding that won't have a cache hit
	embedding := []float64{0.1, 0.2, 0.3}
	result, err := svc.OptimizeRequest(ctx, "new unique query", embedding)
	require.NoError(t, err)

	assert.False(t, result.CacheHit)
	assert.Empty(t, result.CachedResponse)
	assert.Equal(t, "new unique query", result.OriginalPrompt)
}

func TestServiceOptimizeResponse_WithValidationError(t *testing.T) {
	ctx := context.Background()

	config := DefaultConfig()
	config.StructuredOutput.Enabled = true

	svc, err := NewService(config)
	require.NoError(t, err)

	// Create schema requiring name field
	schema := outlines.ObjectSchema(map[string]*outlines.JSONSchema{
		"name": outlines.StringSchema(),
	}, "name")

	// Provide response missing required field
	result, err := svc.OptimizeResponse(ctx, `{"other": "field"}`, nil, "test", schema)
	require.NoError(t, err)

	assert.NotNil(t, result.ValidationResult)
	assert.False(t, result.ValidationResult.Valid)
	assert.Nil(t, result.StructuredOutput)
}

func TestServiceOptimizeResponse_WithoutCache(t *testing.T) {
	ctx := context.Background()

	config := DefaultConfig()
	config.SemanticCache.Enabled = false

	svc, err := NewService(config)
	require.NoError(t, err)

	result, err := svc.OptimizeResponse(ctx, "test response", nil, "test query", nil)
	require.NoError(t, err)

	assert.False(t, result.Cached)
	assert.Equal(t, "test response", result.Content)
}

func TestServiceOptimizeRequest_NoEmbedding(t *testing.T) {
	ctx := context.Background()

	config := DefaultConfig()
	config.SemanticCache.Enabled = true
	config.LlamaIndex.Enabled = false
	config.LangChain.Enabled = false
	config.SGLang.Enabled = false

	svc, err := NewService(config)
	require.NoError(t, err)

	// Request without embedding - should skip cache check
	result, err := svc.OptimizeRequest(ctx, "test query", nil)
	require.NoError(t, err)

	assert.False(t, result.CacheHit)
	assert.Equal(t, "test query", result.OptimizedPrompt)
}

func TestServiceGenerateStructured_GeneratorError(t *testing.T) {
	ctx := context.Background()

	config := DefaultConfig()
	config.StructuredOutput.Enabled = true

	svc, err := NewService(config)
	require.NoError(t, err)

	schema := outlines.StringSchema()
	generator := func(prompt string) (string, error) {
		return "", fmt.Errorf("generator failed")
	}

	_, err = svc.GenerateStructured(ctx, "test", schema, generator)
	assert.Error(t, err)
	assert.Contains(t, err.Error(), "generator failed")
}

func TestServiceGetServiceStatus_WithServices(t *testing.T) {
	ctx := context.Background()

	config := DefaultConfig()
	// Enable services but they won't actually be connected
	config.SGLang.Enabled = true
	config.LlamaIndex.Enabled = true
	config.LangChain.Enabled = true
	config.Guidance.Enabled = true
	config.LMQL.Enabled = true

	svc, err := NewService(config)
	require.NoError(t, err)

	// Get status - will check health of configured services
	status := svc.GetServiceStatus(ctx)

	// Status should be returned (actual health depends on service availability)
	assert.NotNil(t, status)
}

func TestNewService_WithAllServicesEnabled(t *testing.T) {
	config := DefaultConfig()
	config.SGLang.Enabled = true
	config.SGLang.Endpoint = "http://localhost:30000"
	config.LlamaIndex.Enabled = true
	config.LlamaIndex.Endpoint = "http://localhost:8002"
	config.LangChain.Enabled = true
	config.LangChain.Endpoint = "http://localhost:8001"
	config.Guidance.Enabled = true
	config.Guidance.Endpoint = "http://localhost:8003"
	config.LMQL.Enabled = true
	config.LMQL.Endpoint = "http://localhost:8004"

	svc, err := NewService(config)
	require.NoError(t, err)
	assert.NotNil(t, svc)

	// All clients should be initialized
	assert.NotNil(t, svc.sglangClient)
	assert.NotNil(t, svc.llamaindexClient)
	assert.NotNil(t, svc.langchainClient)
	assert.NotNil(t, svc.guidanceClient)
	assert.NotNil(t, svc.lmqlClient)
}

func TestIsComplexTask_ShortPrompts(t *testing.T) {
	// Short prompts should never be complex
	assert.False(t, isComplexTask("hi"))
	assert.False(t, isComplexTask("hello world"))
	assert.False(t, isComplexTask("what is the weather"))
}

func TestIsComplexTask_MediumPromptWithIndicators(t *testing.T) {
	// Prompt must be over 100 chars with indicators
	shortWithIndicator := "implement this function"
	assert.False(t, isComplexTask(shortWithIndicator)) // Too short

	longWithIndicator := "Please implement a complex multi-step data processing pipeline that transforms CSV data into normalized JSON format with validation"
	assert.True(t, isComplexTask(longWithIndicator))
}

func TestServiceStreamEnhanced_WithProgressCallback(t *testing.T) {
	ctx := context.Background()

	config := DefaultConfig()
	config.Streaming.Enabled = true
	config.Streaming.ProgressInterval = 10 * time.Millisecond

	svc, err := NewService(config)
	require.NoError(t, err)

	in := make(chan *streaming.StreamChunk, 5)
	in <- &streaming.StreamChunk{Content: "Hello ", Index: 0}
	in <- &streaming.StreamChunk{Content: "world!", Index: 1}
	in <- &streaming.StreamChunk{Content: "", Index: 2, Done: true}
	close(in)

	var progressCalled atomic.Bool
	progressCallback := func(p *streaming.StreamProgress) {
		progressCalled.Store(true)
	}

	out, getResult := svc.StreamEnhanced(ctx, in, progressCallback)

	// Consume output
	for range out {
	}

	result := getResult()
	assert.NotNil(t, result)
	// Progress callback may or may not be called depending on timing
	_ = progressCalled.Load()
}

func TestServiceOptimizeRequest_WithMockedLlamaIndex(t *testing.T) {
	// Mock LlamaIndex server
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		if r.URL.Path == "/health" {
			w.WriteHeader(http.StatusOK)
			_ = json.NewEncoder(w).Encode(map[string]string{"status": "healthy"})
			return
		}
		if r.URL.Path == "/query" {
			resp := map[string]interface{}{
				"response": "test response",
				"sources": []map[string]interface{}{
					{
						"content":  "relevant context 1",
						"metadata": map[string]string{},
						"score":    0.95,
					},
					{
						"content":  "relevant context 2",
						"metadata": map[string]string{},
						"score":    0.85,
					},
				},
			}
			w.Header().Set("Content-Type", "application/json")
			_ = json.NewEncoder(w).Encode(resp)
			return
		}
		w.WriteHeader(http.StatusNotFound)
	}))
	defer server.Close()

	config := DefaultConfig()
	config.SemanticCache.Enabled = false
	config.LlamaIndex.Enabled = true
	config.LlamaIndex.Endpoint = server.URL
	config.LangChain.Enabled = false
	config.SGLang.Enabled = false

	svc, err := NewService(config)
	require.NoError(t, err)

	ctx := context.Background()
	result, err := svc.OptimizeRequest(ctx, "test query", nil)
	require.NoError(t, err)

	// Should have retrieved context and augmented the prompt
	assert.NotEmpty(t, result.RetrievedContext)
	assert.Contains(t, result.OptimizedPrompt, "Relevant context")
}

func TestServiceOptimizeRequest_WithMockedSGLang(t *testing.T) {
	// Mock SGLang server
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		if r.URL.Path == "/health" {
			w.WriteHeader(http.StatusOK)
			_ = json.NewEncoder(w).Encode(map[string]string{"status": "ok"})
			return
		}
		// Accept any request to warm_prefix and return success
		resp := map[string]interface{}{
			"prefix_id": "test-prefix",
			"cached":    true,
		}
		w.Header().Set("Content-Type", "application/json")
		_ = json.NewEncoder(w).Encode(resp)
	}))
	defer server.Close()

	config := DefaultConfig()
	config.SemanticCache.Enabled = false
	config.LlamaIndex.Enabled = false
	config.LangChain.Enabled = false
	config.SGLang.Enabled = true
	config.SGLang.Endpoint = server.URL

	svc, err := NewService(config)
	require.NoError(t, err)

	ctx := context.Background()
	result, err := svc.OptimizeRequest(ctx, "test query that needs to be long enough for prefix caching", nil)
	require.NoError(t, err)

	// The SGLang integration attempts prefix warming - result depends on API response
	// We just verify the request completes without error
	assert.Equal(t, "test query that needs to be long enough for prefix caching", result.OriginalPrompt)
}

func TestServiceOptimizeRequest_WithMockedLangChain(t *testing.T) {
	// Mock LangChain server
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		if r.URL.Path == "/health" {
			w.WriteHeader(http.StatusOK)
			_ = json.NewEncoder(w).Encode(map[string]string{"status": "healthy"})
			return
		}
		if r.URL.Path == "/decompose" {
			resp := map[string]interface{}{
				"subtasks": []map[string]interface{}{
					{"step": 1, "description": "First step"},
					{"step": 2, "description": "Second step"},
				},
			}
			w.Header().Set("Content-Type", "application/json")
			_ = json.NewEncoder(w).Encode(resp)
			return
		}
		w.WriteHeader(http.StatusOK)
	}))
	defer server.Close()

	config := DefaultConfig()
	config.SemanticCache.Enabled = false
	config.LlamaIndex.Enabled = false
	config.LangChain.Enabled = true
	config.LangChain.Endpoint = server.URL
	config.SGLang.Enabled = false

	svc, err := NewService(config)
	require.NoError(t, err)

	ctx := context.Background()
	// Use a complex task that will trigger decomposition
	complexTask := "Please implement a complex multi-step data processing pipeline that transforms CSV data into normalized JSON format with validation and error handling"
	result, err := svc.OptimizeRequest(ctx, complexTask, nil)
	require.NoError(t, err)

	// Should have decomposed tasks
	assert.NotEmpty(t, result.DecomposedTasks)
}

func TestServiceQueryDocuments_WithOptions(t *testing.T) {
	// Test QueryDocuments with options - covers the options != nil branch
	config := DefaultConfig()
	config.LlamaIndex.Enabled = false

	svc, err := NewService(config)
	require.NoError(t, err)

	ctx := context.Background()
	_, err = svc.QueryDocuments(ctx, "test", nil)
	assert.Error(t, err)
	assert.Contains(t, err.Error(), "not available")
}

// Benchmark tests
func BenchmarkSemanticCacheLookup(b *testing.B) {
	ctx := context.Background()
	config := DefaultConfig()
	config.SemanticCache.Enabled = true
	config.LlamaIndex.Enabled = false
	config.LangChain.Enabled = false
	config.SGLang.Enabled = false

	svc, _ := NewService(config)

	// Pre-populate cache
	for i := 0; i < 100; i++ {
		embedding := make([]float64, 128)
		embedding[i%128] = 1.0
		_, _ = svc.semanticCache.Set(ctx, "query", "response", embedding, nil)
	}

	embedding := []float64{1.0}
	for i := 1; i < 128; i++ {
		embedding = append(embedding, 0.0)
	}

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		_, _ = svc.OptimizeRequest(ctx, "test query", embedding)
	}
}

func BenchmarkStreamEnhanced(b *testing.B) {
	ctx := context.Background()
	config := DefaultConfig()
	config.Streaming.Enabled = true

	svc, _ := NewService(config)

	b.ResetTimer()
	for i := 0; i < b.N; i++ {
		in := make(chan *streaming.StreamChunk, 10)
		go func() {
			for j := 0; j < 10; j++ {
				in <- &streaming.StreamChunk{Content: "word ", Index: j}
			}
			in <- &streaming.StreamChunk{Done: true, Index: 10}
			close(in)
		}()

		out, _ := svc.StreamEnhanced(ctx, in, nil)
		for range out {
		}
	}
}

// TestServiceConcurrentCacheAccess tests thread safety of cache operations
func TestServiceConcurrentCacheAccess(t *testing.T) {
	ctx := context.Background()
	config := DefaultConfig()
	config.SemanticCache.Enabled = true
	config.LlamaIndex.Enabled = false
	config.LangChain.Enabled = false
	config.SGLang.Enabled = false

	svc, err := NewService(config)
	require.NoError(t, err)

	// Pre-populate cache with some entries
	for i := 0; i < 10; i++ {
		embedding := make([]float64, 128)
		embedding[i%128] = 1.0
		_, _ = svc.semanticCache.Set(ctx, fmt.Sprintf("query-%d", i), "response", embedding, nil)
	}

	var wg sync.WaitGroup
	errorChan := make(chan error, 100)

	// Concurrent reads
	for i := 0; i < 50; i++ {
		wg.Add(1)
		go func(idx int) {
			defer wg.Done()
			embedding := make([]float64, 128)
			embedding[idx%10] = 1.0
			_, err := svc.OptimizeRequest(ctx, "concurrent query", embedding)
			if err != nil {
				errorChan <- err
			}
		}(i)
	}

	// Concurrent writes
	for i := 0; i < 50; i++ {
		wg.Add(1)
		go func(idx int) {
			defer wg.Done()
			embedding := make([]float64, 128)
			embedding[(idx+50)%128] = 1.0
			_, err := svc.OptimizeResponse(ctx, "concurrent response", embedding, "query", nil)
			if err != nil {
				errorChan <- err
			}
		}(i)
	}

	// Concurrent status checks
	for i := 0; i < 20; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			svc.GetServiceStatus(ctx)
			svc.GetCacheStats()
		}()
	}

	wg.Wait()
	close(errorChan)

	var errors []error
	for err := range errorChan {
		errors = append(errors, err)
	}
	assert.Empty(t, errors, "Expected no errors during concurrent access")
}

// TestServiceChainedOptimization tests multiple optimization stages working together
func TestServiceChainedOptimization(t *testing.T) {
	// Mock servers for all services
	llamaServer := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		if r.URL.Path == "/health" {
			_ = json.NewEncoder(w).Encode(map[string]string{"status": "healthy"})
			return
		}
		if r.URL.Path == "/query" {
			resp := map[string]interface{}{
				"answer": "Context retrieved",
				"sources": []map[string]interface{}{
					{"content": "Relevant context from documents", "score": 0.95},
				},
			}
			w.Header().Set("Content-Type", "application/json")
			_ = json.NewEncoder(w).Encode(resp)
			return
		}
		w.WriteHeader(http.StatusNotFound)
	}))
	defer llamaServer.Close()

	langchainServer := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		if r.URL.Path == "/health" {
			_ = json.NewEncoder(w).Encode(map[string]string{"status": "healthy"})
			return
		}
		if r.URL.Path == "/decompose" {
			resp := map[string]interface{}{
				"subtasks": []map[string]interface{}{
					{"id": 1, "description": "First subtask"},
					{"id": 2, "description": "Second subtask"},
				},
				"reasoning": "Task decomposed successfully",
			}
			w.Header().Set("Content-Type", "application/json")
			_ = json.NewEncoder(w).Encode(resp)
			return
		}
		w.WriteHeader(http.StatusNotFound)
	}))
	defer langchainServer.Close()

	sglangServer := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		if r.URL.Path == "/health" {
			_ = json.NewEncoder(w).Encode(map[string]string{"status": "healthy"})
			return
		}
		if r.URL.Path == "/v1/chat/completions" {
			resp := map[string]interface{}{
				"id":      "test",
				"choices": []map[string]interface{}{{"message": map[string]string{"content": ""}}},
			}
			w.Header().Set("Content-Type", "application/json")
			_ = json.NewEncoder(w).Encode(resp)
			return
		}
		w.WriteHeader(http.StatusNotFound)
	}))
	defer sglangServer.Close()

	config := DefaultConfig()
	config.SemanticCache.Enabled = true
	config.LlamaIndex.Enabled = true
	config.LlamaIndex.Endpoint = llamaServer.URL
	config.LangChain.Enabled = true
	config.LangChain.Endpoint = langchainServer.URL
	config.SGLang.Enabled = true
	config.SGLang.Endpoint = sglangServer.URL

	svc, err := NewService(config)
	require.NoError(t, err)

	// Mark services as available
	svc.mu.Lock()
	svc.serviceStatus["llamaindex"] = true
	svc.serviceStatus["langchain"] = true
	svc.serviceStatus["sglang"] = true
	svc.lastHealthCheck["llamaindex"] = time.Now()
	svc.lastHealthCheck["langchain"] = time.Now()
	svc.lastHealthCheck["sglang"] = time.Now()
	svc.mu.Unlock()

	ctx := context.Background()

	// Test with a complex task that triggers all optimizations
	complexPrompt := "Please implement a comprehensive data processing pipeline that transforms raw CSV data into normalized JSON format, including validation, error handling, and logging. This should support batch processing and real-time streaming modes."

	result, err := svc.OptimizeRequest(ctx, complexPrompt, nil)
	require.NoError(t, err)

	// Verify multiple optimizations were applied
	assert.NotEmpty(t, result.RetrievedContext)
	assert.NotEmpty(t, result.DecomposedTasks)
	assert.True(t, result.WarmPrefix)
}

// TestServiceErrorRecovery tests service behavior when external services fail
func TestServiceErrorRecovery(t *testing.T) {
	failCount := 0
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		failCount++
		if failCount <= 2 {
			w.WriteHeader(http.StatusInternalServerError)
			return
		}
		// Recover after 2 failures
		_ = json.NewEncoder(w).Encode(map[string]string{"status": "healthy"})
	}))
	defer server.Close()

	config := DefaultConfig()
	config.LlamaIndex.Enabled = true
	config.LlamaIndex.Endpoint = server.URL
	config.Fallback.RetryUnavailableAfter = 10 * time.Millisecond

	svc, err := NewService(config)
	require.NoError(t, err)

	ctx := context.Background()

	// First request should handle the failure gracefully
	result, err := svc.OptimizeRequest(ctx, "test query", nil)
	require.NoError(t, err)
	assert.Equal(t, "test query", result.OptimizedPrompt) // Falls back to original
}

// TestServiceCacheInvalidation tests cache invalidation scenarios
func TestServiceCacheInvalidation(t *testing.T) {
	ctx := context.Background()
	config := DefaultConfig()
	config.SemanticCache.Enabled = true
	config.LlamaIndex.Enabled = false
	config.LangChain.Enabled = false
	config.SGLang.Enabled = false

	svc, err := NewService(config)
	require.NoError(t, err)

	// Add entries to cache
	embedding1 := []float64{1.0, 0.0, 0.0}
	embedding2 := []float64{0.9, 0.1, 0.0}
	embedding3 := []float64{0.0, 1.0, 0.0}

	_, _ = svc.semanticCache.Set(ctx, "query1", "response1", embedding1, map[string]interface{}{"category": "test"})
	_, _ = svc.semanticCache.Set(ctx, "query2", "response2", embedding2, map[string]interface{}{"category": "test"})
	_, _ = svc.semanticCache.Set(ctx, "query3", "response3", embedding3, map[string]interface{}{"category": "prod"})

	assert.Equal(t, 3, svc.semanticCache.Size())

	// Verify cache hits work
	hit, err := svc.semanticCache.Get(ctx, embedding1)
	require.NoError(t, err)
	assert.Equal(t, "response1", hit.Entry.Response)
}

// TestServiceHealthCheckInterval tests health check caching behavior
func TestServiceHealthCheckInterval(t *testing.T) {
	callCount := 0
	server := httptest.NewServer(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		callCount++
		_ = json.NewEncoder(w).Encode(map[string]string{"status": "healthy"})
	}))
	defer server.Close()

	config := DefaultConfig()
	config.LlamaIndex.Enabled = true
	config.LlamaIndex.Endpoint = server.URL
	config.Fallback.HealthCheckInterval = 1 * time.Hour // Long interval

	svc, err := NewService(config)
	require.NoError(t, err)

	ctx := context.Background()

	// First status check
	svc.GetServiceStatus(ctx)
	firstCount := callCount

	// Second status check (should use cached result)
	svc.GetServiceStatus(ctx)
	secondCount := callCount

	// Third status check (should still use cached result)
	svc.GetServiceStatus(ctx)

	// The health check should have been called at most once per service per check cycle
	assert.GreaterOrEqual(t, firstCount, 0)
	assert.Equal(t, firstCount, secondCount) // No additional calls due to caching
}

// TestMinFunctionEdgeCases tests the min helper function edge cases
func TestMinFunctionEdgeCases(t *testing.T) {
	assert.Equal(t, 0, min(0, 0))
	assert.Equal(t, -10, min(-10, -5))
	assert.Equal(t, -10, min(-5, -10))
	assert.Equal(t, 0, min(0, 100))
	assert.Equal(t, 0, min(100, 0))
}

// TestContainsIgnoreCaseEdgeCases tests containsIgnoreCase edge cases
func TestContainsIgnoreCaseEdgeCases(t *testing.T) {
	// Empty strings
	assert.True(t, containsIgnoreCase("", ""))
	assert.True(t, containsIgnoreCase("test", ""))
	assert.False(t, containsIgnoreCase("", "test"))

	// Exact match
	assert.True(t, containsIgnoreCase("hello", "hello"))

	// Substring longer than string
	assert.False(t, containsIgnoreCase("hi", "hello world"))
}

// TestServiceOptimizeRequestWithEmptyPrompt tests handling of empty prompts
func TestServiceOptimizeRequestWithEmptyPrompt(t *testing.T) {
	ctx := context.Background()
	config := DefaultConfig()
	config.SemanticCache.Enabled = false
	config.LlamaIndex.Enabled = false
	config.LangChain.Enabled = false
	config.SGLang.Enabled = false

	svc, err := NewService(config)
	require.NoError(t, err)

	result, err := svc.OptimizeRequest(ctx, "", nil)
	require.NoError(t, err)
	assert.Equal(t, "", result.OriginalPrompt)
	assert.Equal(t, "", result.OptimizedPrompt)
}

// TestServiceOptimizeResponseWithEmptyResponse tests handling of empty responses
func TestServiceOptimizeResponseWithEmptyResponse(t *testing.T) {
	ctx := context.Background()
	config := DefaultConfig()
	config.SemanticCache.Enabled = true

	svc, err := NewService(config)
	require.NoError(t, err)

	embedding := []float64{1.0, 0.0, 0.0}
	result, err := svc.OptimizeResponse(ctx, "", embedding, "query", nil)
	require.NoError(t, err)
	assert.Equal(t, "", result.Content)
}

// TestServiceMultipleStreamsSequentially tests multiple stream operations
func TestServiceMultipleStreamsSequentially(t *testing.T) {
	ctx := context.Background()
	config := DefaultConfig()
	config.Streaming.Enabled = true

	svc, err := NewService(config)
	require.NoError(t, err)

	for i := 0; i < 5; i++ {
		in := make(chan *streaming.StreamChunk, 3)
		in <- &streaming.StreamChunk{Content: fmt.Sprintf("Stream %d ", i), Index: 0}
		in <- &streaming.StreamChunk{Content: "content", Index: 1}
		in <- &streaming.StreamChunk{Done: true, Index: 2}
		close(in)

		out, getResult := svc.StreamEnhanced(ctx, in, nil)

		// Consume output
		for range out {
		}

		result := getResult()
		assert.NotNil(t, result)
		assert.Contains(t, result.FullContent, fmt.Sprintf("Stream %d", i))
	}
}

// TestIsComplexTaskWithVariousIndicators tests all complexity indicators
func TestIsComplexTaskWithVariousIndicators(t *testing.T) {
	// Base prefix to make prompt > 100 chars
	basePrefix := "Please help me with the following task that requires careful consideration and detailed analysis: "

	testCases := []struct {
		indicator string
		expected  bool
	}{
		{"step by step", true},
		{"multi-step", true},
		{"first, then", true},
		{"implement", true},
		{"create a", true},
		{"build a", true},
		{"design a", true},
		{"analyze", true},
	}

	for _, tc := range testCases {
		t.Run(tc.indicator, func(t *testing.T) {
			prompt := basePrefix + "I need to " + tc.indicator + " something complex"
			result := isComplexTask(prompt)
			assert.Equal(t, tc.expected, result)
		})
	}
}

// TestServiceWithDisabledFallback tests behavior when fallback is disabled
func TestServiceWithDisabledFallback(t *testing.T) {
	config := DefaultConfig()
	config.Fallback.OnServiceUnavailable = "error"
	config.SemanticCache.Enabled = false
	config.LlamaIndex.Enabled = false
	config.LangChain.Enabled = false
	config.SGLang.Enabled = false

	svc, err := NewService(config)
	require.NoError(t, err)

	ctx := context.Background()
	result, err := svc.OptimizeRequest(ctx, "test", nil)
	require.NoError(t, err)
	assert.Equal(t, "test", result.OptimizedPrompt)
}

// TestServiceCacheStatsAccuracy tests the accuracy of cache statistics
func TestServiceCacheStatsAccuracy(t *testing.T) {
	ctx := context.Background()
	config := DefaultConfig()
	config.SemanticCache.Enabled = true
	config.LlamaIndex.Enabled = false
	config.LangChain.Enabled = false
	config.SGLang.Enabled = false

	svc, err := NewService(config)
	require.NoError(t, err)

	// Add an entry
	embedding := []float64{1.0, 0.0, 0.0}
	_, _ = svc.semanticCache.Set(ctx, "query", "response", embedding, nil)

	// Make some hits and misses
	for i := 0; i < 5; i++ {
		_, _ = svc.OptimizeRequest(ctx, "query", embedding) // Hit
	}

	differentEmbedding := []float64{0.0, 1.0, 0.0}
	for i := 0; i < 3; i++ {
		_, _ = svc.OptimizeRequest(ctx, "other query", differentEmbedding) // Miss
	}

	stats := svc.GetCacheStats()
	assert.Equal(t, int64(5), svc.cacheHits)
	assert.Equal(t, int64(3), svc.cacheMisses)
	assert.True(t, stats["enabled"].(bool))
}

// TestServiceContextCancellation tests behavior when context is cancelled
func TestServiceContextCancellation(t *testing.T) {
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()
	config := DefaultConfig()
	config.Streaming.Enabled = true

	svc, err := NewService(config)
	require.NoError(t, err)

	in := make(chan *streaming.StreamChunk, 100)
	go func() {
		for i := 0; i < 100; i++ {
			select {
			case <-ctx.Done():
				close(in)
				return
			case in <- &streaming.StreamChunk{Content: "chunk ", Index: i}:
			}
		}
		close(in)
	}()

	out, _ := svc.StreamEnhanced(ctx, in, nil)

	// Cancel after receiving a few chunks
	received := 0
	for range out {
		received++
		if received > 5 {
			cancel()
		}
	}

	// Should have stopped before receiving all 100 chunks
	assert.Less(t, received, 100)
}
