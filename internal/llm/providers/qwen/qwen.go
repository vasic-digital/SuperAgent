package qwen

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"math/rand"
	"net/http"
	"time"

	"github.com/superagent/superagent/internal/models"
)

// RetryConfig defines retry behavior for API calls
type RetryConfig struct {
	MaxRetries   int
	InitialDelay time.Duration
	MaxDelay     time.Duration
	Multiplier   float64
}

// DefaultRetryConfig returns sensible defaults for Qwen API retry behavior
func DefaultRetryConfig() RetryConfig {
	return RetryConfig{
		MaxRetries:   3,
		InitialDelay: 1 * time.Second,
		MaxDelay:     30 * time.Second,
		Multiplier:   2.0,
	}
}

// QwenProvider implements the LLMProvider interface for Alibaba Cloud Qwen
type QwenProvider struct {
	apiKey      string
	baseURL     string
	model       string
	httpClient  *http.Client
	retryConfig RetryConfig
}

// QwenRequest represents a request to the Qwen API
type QwenRequest struct {
	Model       string        `json:"model"`
	Messages    []QwenMessage `json:"messages"`
	Stream      bool          `json:"stream,omitempty"`
	Temperature float64       `json:"temperature,omitempty"`
	MaxTokens   int           `json:"max_tokens,omitempty"`
	TopP        float64       `json:"top_p,omitempty"`
	Stop        []string      `json:"stop,omitempty"`
}

// QwenMessage represents a message in the Qwen API format
type QwenMessage struct {
	Role    string `json:"role"`
	Content string `json:"content"`
}

// QwenResponse represents a response from the Qwen API
type QwenResponse struct {
	ID      string       `json:"id"`
	Object  string       `json:"object"`
	Created int64        `json:"created"`
	Model   string       `json:"model"`
	Choices []QwenChoice `json:"choices"`
	Usage   QwenUsage    `json:"usage"`
}

// QwenChoice represents a choice in the Qwen response
type QwenChoice struct {
	Index        int         `json:"index"`
	Message      QwenMessage `json:"message"`
	FinishReason string      `json:"finish_reason"`
}

// QwenUsage represents token usage in the Qwen response
type QwenUsage struct {
	PromptTokens     int `json:"prompt_tokens"`
	CompletionTokens int `json:"completion_tokens"`
	TotalTokens      int `json:"total_tokens"`
}

// QwenError represents an error from the Qwen API
type QwenError struct {
	Error struct {
		Message string `json:"message"`
		Type    string `json:"type"`
		Code    string `json:"code"`
	} `json:"error"`
}

// NewQwenProvider creates a new Qwen provider instance
func NewQwenProvider(apiKey, baseURL, model string) *QwenProvider {
	return NewQwenProviderWithRetry(apiKey, baseURL, model, DefaultRetryConfig())
}

// NewQwenProviderWithRetry creates a new Qwen provider instance with custom retry config
func NewQwenProviderWithRetry(apiKey, baseURL, model string, retryConfig RetryConfig) *QwenProvider {
	if baseURL == "" {
		baseURL = "https://dashscope.aliyuncs.com/api/v1"
	}
	if model == "" {
		model = "qwen-turbo"
	}

	return &QwenProvider{
		apiKey:  apiKey,
		baseURL: baseURL,
		model:   model,
		httpClient: &http.Client{
			Timeout: 60 * time.Second,
		},
		retryConfig: retryConfig,
	}
}

// Complete implements the LLMProvider interface
func (q *QwenProvider) Complete(ctx context.Context, req *models.LLMRequest) (*models.LLMResponse, error) {
	// Convert internal request to Qwen format
	qwenReq := q.convertToQwenRequest(req)

	// Make API call
	resp, err := q.makeRequest(ctx, qwenReq)
	if err != nil {
		return nil, fmt.Errorf("failed to complete request: %w", err)
	}

	// Convert response back to internal format
	return q.convertFromQwenResponse(resp, req.ID)
}

// CompleteStream implements streaming completion for Qwen
func (q *QwenProvider) CompleteStream(ctx context.Context, req *models.LLMRequest) (<-chan *models.LLMResponse, error) {
	responseChan := make(chan *models.LLMResponse, 10)

	go func() {
		defer close(responseChan)

		// For now, simulate streaming by getting the complete response and sending it in chunks
		// In a full implementation, this would use Qwen's actual streaming API

		response, err := q.Complete(ctx, req)
		if err != nil {
			// For streaming, we just close the channel on error
			return
		}

		// Simulate streaming by breaking the response into chunks
		content := response.Content
		chunkSize := 50 // characters per chunk

		for i := 0; i < len(content); i += chunkSize {
			end := i + chunkSize
			if end > len(content) {
				end = len(content)
			}

			chunk := content[i:end]

			streamResponse := &models.LLMResponse{
				ID:           fmt.Sprintf("%s-chunk-%d", response.ID, i/chunkSize),
				ProviderID:   response.ProviderID,
				ProviderName: response.ProviderName,
				Content:      chunk,
				Confidence:   response.Confidence,
				TokensUsed:   response.TokensUsed / (len(content)/chunkSize + 1), // Approximate token distribution
				ResponseTime: response.ResponseTime / int64(len(content)/chunkSize+1),
				FinishReason: func() string {
					if end >= len(content) {
						return "stop"
					}
					return ""
				}(),
				CreatedAt: time.Now(),
			}

			select {
			case responseChan <- streamResponse:
			case <-ctx.Done():
				return
			}

			// Small delay to simulate streaming
			time.Sleep(50 * time.Millisecond)
		}
	}()

	return responseChan, nil
}

// HealthCheck implements health checking for the Qwen provider
func (q *QwenProvider) HealthCheck() error {
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	// Simple health check - try to get models list
	req, err := http.NewRequestWithContext(ctx, "GET", q.baseURL+"/models", nil)
	if err != nil {
		return fmt.Errorf("failed to create health check request: %w", err)
	}

	req.Header.Set("Authorization", "Bearer "+q.apiKey)
	req.Header.Set("Content-Type", "application/json")

	resp, err := q.httpClient.Do(req)
	if err != nil {
		return fmt.Errorf("health check request failed: %w", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return fmt.Errorf("health check failed with status: %d", resp.StatusCode)
	}

	return nil
}

// GetCapabilities returns the capabilities of the Qwen provider
func (q *QwenProvider) GetCapabilities() *models.ProviderCapabilities {
	return &models.ProviderCapabilities{
		SupportedModels: []string{
			"qwen-turbo",
			"qwen-plus",
			"qwen-max",
			"qwen-max-longcontext",
		},
		SupportedFeatures: []string{
			"text_completion",
			"chat",
			"function_calling",
		},
		SupportedRequestTypes: []string{
			"text_completion",
			"chat",
		},
		SupportsStreaming:       true,
		SupportsFunctionCalling: true,
		SupportsVision:          false,
		SupportsTools:           true,
		SupportsSearch:          false,
		SupportsReasoning:       true,
		SupportsCodeCompletion:  true,
		SupportsCodeAnalysis:    true,
		SupportsRefactoring:     false,
		Limits: models.ModelLimits{
			MaxTokens:             6000,
			MaxInputLength:        30000,
			MaxOutputLength:       2000,
			MaxConcurrentRequests: 50,
		},
		Metadata: map[string]string{
			"provider":     "Alibaba Cloud",
			"model_family": "Qwen",
			"api_version":  "v1",
		},
	}
}

// ValidateConfig validates the provider configuration
func (q *QwenProvider) ValidateConfig(config map[string]interface{}) (bool, []string) {
	var errors []string

	if q.apiKey == "" {
		errors = append(errors, "API key is required")
	}

	if q.baseURL == "" {
		errors = append(errors, "base URL is required")
	}

	if q.model == "" {
		errors = append(errors, "model is required")
	}

	return len(errors) == 0, errors
}

// convertToQwenRequest converts internal request format to Qwen API format
func (q *QwenProvider) convertToQwenRequest(req *models.LLMRequest) *QwenRequest {
	messages := make([]QwenMessage, 0, len(req.Messages))

	// Add system message if present in prompt
	if req.Prompt != "" {
		messages = append(messages, QwenMessage{
			Role:    "system",
			Content: req.Prompt,
		})
	}

	// Convert internal messages
	for _, msg := range req.Messages {
		messages = append(messages, QwenMessage{
			Role:    msg.Role,
			Content: msg.Content,
		})
	}

	return &QwenRequest{
		Model:       q.model,
		Messages:    messages,
		Stream:      false,
		Temperature: req.ModelParams.Temperature,
		MaxTokens:   req.ModelParams.MaxTokens,
		TopP:        req.ModelParams.TopP,
		Stop:        req.ModelParams.StopSequences,
	}
}

// convertFromQwenResponse converts Qwen API response to internal format
func (q *QwenProvider) convertFromQwenResponse(resp *QwenResponse, requestID string) (*models.LLMResponse, error) {
	if len(resp.Choices) == 0 {
		return nil, fmt.Errorf("no choices returned from Qwen API")
	}

	choice := resp.Choices[0]

	return &models.LLMResponse{
		ID:           resp.ID,
		RequestID:    requestID,
		ProviderID:   "qwen",
		ProviderName: "Qwen",
		Content:      choice.Message.Content,
		Confidence:   0.85, // Qwen doesn't provide confidence scores
		TokensUsed:   resp.Usage.TotalTokens,
		ResponseTime: time.Now().UnixMilli() - (resp.Created * 1000),
		FinishReason: choice.FinishReason,
		Metadata: map[string]interface{}{
			"model":             resp.Model,
			"object":            resp.Object,
			"prompt_tokens":     resp.Usage.PromptTokens,
			"completion_tokens": resp.Usage.CompletionTokens,
		},
		CreatedAt: time.Now(),
	}, nil
}

// makeRequest sends a request to the Qwen API with retry logic
func (q *QwenProvider) makeRequest(ctx context.Context, req *QwenRequest) (*QwenResponse, error) {
	jsonData, err := json.Marshal(req)
	if err != nil {
		return nil, fmt.Errorf("failed to marshal request: %w", err)
	}

	var lastErr error
	delay := q.retryConfig.InitialDelay

	for attempt := 0; attempt <= q.retryConfig.MaxRetries; attempt++ {
		// Check context before making request
		select {
		case <-ctx.Done():
			return nil, fmt.Errorf("context cancelled: %w", ctx.Err())
		default:
		}

		httpReq, err := http.NewRequestWithContext(ctx, "POST", q.baseURL+"/services/aigc/text-generation/generation", bytes.NewBuffer(jsonData))
		if err != nil {
			return nil, fmt.Errorf("failed to create HTTP request: %w", err)
		}

		httpReq.Header.Set("Authorization", "Bearer "+q.apiKey)
		httpReq.Header.Set("Content-Type", "application/json")

		resp, err := q.httpClient.Do(httpReq)
		if err != nil {
			lastErr = fmt.Errorf("HTTP request failed: %w", err)
			if attempt < q.retryConfig.MaxRetries {
				q.waitWithJitter(ctx, delay)
				delay = q.nextDelay(delay)
				continue
			}
			return nil, lastErr
		}

		// Check for retryable status codes
		if isRetryableStatus(resp.StatusCode) && attempt < q.retryConfig.MaxRetries {
			resp.Body.Close()
			lastErr = fmt.Errorf("HTTP %d: retryable error", resp.StatusCode)
			q.waitWithJitter(ctx, delay)
			delay = q.nextDelay(delay)
			continue
		}

		body, err := io.ReadAll(resp.Body)
		resp.Body.Close()
		if err != nil {
			return nil, fmt.Errorf("failed to read response body: %w", err)
		}

		if resp.StatusCode != http.StatusOK {
			var qwenErr QwenError
			if err := json.Unmarshal(body, &qwenErr); err == nil && qwenErr.Error.Message != "" {
				return nil, fmt.Errorf("Qwen API error: %s (%s)", qwenErr.Error.Message, qwenErr.Error.Type)
			}
			return nil, fmt.Errorf("Qwen API returned status %d: %s", resp.StatusCode, string(body))
		}

		var qwenResp QwenResponse
		if err := json.Unmarshal(body, &qwenResp); err != nil {
			return nil, fmt.Errorf("failed to unmarshal response: %w", err)
		}

		return &qwenResp, nil
	}

	return nil, fmt.Errorf("all %d retry attempts failed: %w", q.retryConfig.MaxRetries+1, lastErr)
}

// isRetryableStatus returns true for HTTP status codes that warrant a retry
func isRetryableStatus(statusCode int) bool {
	switch statusCode {
	case http.StatusTooManyRequests, // 429 - Rate limited
		http.StatusInternalServerError, // 500
		http.StatusBadGateway,          // 502
		http.StatusServiceUnavailable,  // 503
		http.StatusGatewayTimeout:      // 504
		return true
	default:
		return false
	}
}

// waitWithJitter waits for the specified duration plus random jitter
func (q *QwenProvider) waitWithJitter(ctx context.Context, delay time.Duration) {
	// Add 10% jitter
	jitter := time.Duration(rand.Float64() * 0.1 * float64(delay))
	select {
	case <-ctx.Done():
	case <-time.After(delay + jitter):
	}
}

// nextDelay calculates the next delay using exponential backoff
func (q *QwenProvider) nextDelay(currentDelay time.Duration) time.Duration {
	nextDelay := time.Duration(float64(currentDelay) * q.retryConfig.Multiplier)
	if nextDelay > q.retryConfig.MaxDelay {
		nextDelay = q.retryConfig.MaxDelay
	}
	return nextDelay
}
