services:
  # Mock LLM Server for testing (provides OpenAI-compatible API)
  mock-llm:
    build:
      context: ./tests/mocks/llm-mock-server
      dockerfile: Dockerfile
    container_name: superagent-mock-llm
    ports:
      - "${MOCK_LLM_PORT:-18081}:8081"
    environment:
      PORT: 8081
    networks:
      - superagent-network
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8081/health"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped

  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: superagent-postgres
    environment:
      POSTGRES_DB: superagent_db
      POSTGRES_USER: superagent
      POSTGRES_PASSWORD: superagent123
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8"
    ports:
      - "${POSTGRES_PORT:-15432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    networks:
      - superagent-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U superagent -d superagent_db"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: superagent-redis
    command: redis-server --requirepass superagent123 --appendonly yes
    ports:
      - "${REDIS_PORT:-16379}:6379"
    volumes:
      - redis_data:/data
    networks:
      - superagent-network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Ollama for local LLM testing (free, no API keys needed)
  ollama:
    image: ollama/ollama:latest
    container_name: superagent-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - superagent-network
    environment:
      - OLLAMA_HOST=0.0.0.0
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # SuperAgent Application
  superagent:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: superagent-app
    ports:
      - "8080:8080"
    environment:
      # Server Configuration
      PORT: 8080
      SUPERAGENT_API_KEY: test-api-key-for-development

      # JWT Configuration
      JWT_SECRET: development-jwt-secret-key-change-in-production

      # Database Configuration
      DB_HOST: postgres
      DB_PORT: 5432
      DB_USER: superagent
      DB_PASSWORD: superagent123
      DB_NAME: superagent_db

      # Redis Configuration
      REDIS_HOST: redis
      REDIS_PORT: 6379
      REDIS_PASSWORD: superagent123

      # LLM Provider Configuration (using mock server for testing)
      # All providers point to mock-llm server for deterministic testing
      CLAUDE_API_KEY: "mock-api-key"
      CLAUDE_BASE_URL: http://mock-llm:8081/v1
      DEEPSEEK_API_KEY: "mock-api-key"
      DEEPSEEK_BASE_URL: http://mock-llm:8081/v1
      GEMINI_API_KEY: "mock-api-key"
      GEMINI_BASE_URL: http://mock-llm:8081/v1
      QWEN_API_KEY: "mock-api-key"
      QWEN_BASE_URL: http://mock-llm:8081/v1
      ZAI_API_KEY: "mock-api-key"
      ZAI_BASE_URL: http://mock-llm:8081/v1

      # Ollama Configuration (also pointing to mock server)
      OLLAMA_BASE_URL: http://mock-llm:8081
      OLLAMA_MODEL: mock-llama-3

      # Cognee Configuration (disabled for testing)
      COGNEE_BASE_URL: ""
      COGNEE_API_KEY: ""
      COGNEE_AUTO_COGNIFY: false

      # Plugin Configuration
      PLUGIN_WATCH_PATHS: /app/plugins

      # Models.dev Configuration for Testing
      MODELSDEV_ENABLED: false
      MODELSDEV_API_KEY: ""
      MODELSDEV_BASE_URL: "https://api.test.models.dev/v1"
      MODELSDEV_REFRESH_INTERVAL: "5m"
      MODELSDEV_CACHE_TTL: "1m"
      MODELSDEV_BATCH_SIZE: 10
      MODELSDEV_MAX_RETRIES: 1
      MODELSDEV_AUTO_REFRESH: false
      MODELSDEV_TIMEOUT: 5
      MODELSDEV_USER_AGENT: "SuperAgent-Test/1.0"
      MODELSDEV_RATE_LIMIT: 5

      # Test Environment
      GIN_MODE: release
      LOG_LEVEL: info
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      mock-llm:
        condition: service_healthy
      ollama:
        condition: service_healthy
    volumes:
      - ./plugins:/app/plugins
    networks:
      - superagent-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Prometheus Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: superagent-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - superagent-network
    restart: unless-stopped

  # Grafana Dashboard
  grafana:
    image: grafana/grafana:latest
    container_name: superagent-grafana
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin123
      GF_USERS_ALLOW_SIGN_UP: false
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docs/monitoring/grafana-dashboard.json:/etc/grafana/provisioning/dashboards/superagent.json
      - ./monitoring/grafana-datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml
      - ./monitoring/grafana-dashboards.yml:/etc/grafana/provisioning/dashboards/dashboards.yml
    networks:
      - superagent-network
    depends_on:
      - prometheus
    restart: unless-stopped

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  ollama_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

networks:
  superagent-network:
    driver: bridge