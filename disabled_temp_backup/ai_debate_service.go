package services

import (
	"context"
	"fmt"
	"sync"
	"time"

	"github.com/sirupsen/logrus"
	"github.com/superagent/superagent/internal/config"
	"github.com/superagent/superagent/internal/llm"
	"github.com/superagent/superagent/internal/models"
	"github.com/superagent/superagent/internal/repository"
)

// AIDebateService manages AI debate sessions with multiple participants
type AIDebateService struct {
	config        *config.AIDebateConfig
	llmProviders  map[string]llm.LLMProvider
	cogneeClient  *CogneeClient
	repository    repository.Repository
	logger        *logrus.Logger
	metrics       *DebateMetrics
	memoryManager *DebateMemoryManager
}

// DebateMetrics tracks debate performance metrics
type DebateMetrics struct {
	TotalDebates      int64
	SuccessfulDebates int64
	FailedDebates     int64
	AverageDuration   time.Duration
	ConsensusReached  int64
	QualityScore      float64
	mu                sync.RWMutex
}

// DebateSession represents an active debate session
type DebateSession struct {
	ID           string
	RequestID    string
	Topic        string
	Participants []DebateParticipant
	Rounds       []DebateRound
	StartTime    time.Time
	EndTime      *time.Time
	Status       string // "active", "completed", "failed"
	Consensus    *ConsensusResult
	FinalResult  *DebateResult
}

// DebateParticipant represents a participant in a debate
type DebateParticipant struct {
	Config      *config.DebateParticipant
	Provider    llm.LLMProvider
	Responses   []ParticipantResponse
	Score       float64
	Reliability float64
}

// DebateRound represents a single round of debate
type DebateRound struct {
	Number    int
	StartTime time.Time
	EndTime   *time.Time
	Responses []ParticipantResponse
	Consensus *ConsensusResult
}

// ParticipantResponse represents a participant's response in a debate round
type ParticipantResponse struct {
	ParticipantName string
	LLMName         string
	Content         string
	Confidence      float64
	QualityScore    float64
	ResponseTime    time.Duration
	RoundNumber     int
	Timestamp       time.Time
	CogneeEnhanced  bool
	Metadata        map[string]interface{}
}

// ConsensusResult represents the consensus analysis for a debate round
type ConsensusResult struct {
	Reached         bool
	ConsensusLevel  float64
	AgreementScore  float64
	QualityScore    float64
	Summary         string
	KeyPoints       []string
	Disagreements   []string
	Recommendations []string
	CogneeInsights  *CogneeInsights
}

// CogneeInsights represents insights generated by Cognee AI
type CogneeInsights struct {
	SentimentAnalysis map[string]float64
	EntityExtraction  []string
	TopicModeling     []string
	CoherenceScore    float64
	RelevanceScore    float64
	InnovationScore   float64
	Summary           string
}

// DebateResult represents the final result of a debate
type DebateResult struct {
	SessionID       string
	Topic           string
	Consensus       *ConsensusResult
	BestResponse    ParticipantResponse
	AllResponses    []ParticipantResponse
	Duration        time.Duration
	RoundsConducted int
	FinalScore      float64
	QualityMetrics  map[string]float64
	Recommendations []string
}

// CogneeClient provides integration with Cognee AI for response enhancement
type CogneeClient struct {
	config  *config.CogneeDebateConfig
	enabled bool
	logger  *logrus.Logger
}

// DebateMemoryManager manages memory and context for debates
type DebateMemoryManager struct {
	maxContextLength int
	retentionTime    time.Duration
	memoryStore      map[string][]DebateMemory
	mu               sync.RWMutex
}

// DebateMemory represents a memory entry for a debate
type DebateMemory struct {
	SessionID   string
	Topic       string
	Content     string
	Timestamp   time.Time
	Relevance   float64
	Participant string
}

// NewAIDebateService creates a new AI debate service
func NewAIDebateService(cfg *config.AIDebateConfig, repo repository.Repository, logger *logrus.Logger) (*AIDebateService, error) {
	if cfg == nil {
		return nil, fmt.Errorf("configuration is required")
	}

	if err := cfg.Validate(); err != nil {
		return nil, fmt.Errorf("invalid configuration: %w", err)
	}

	service := &AIDebateService{
		config:       cfg,
		llmProviders: make(map[string]llm.LLMProvider),
		repository:   repo,
		logger:       logger,
		metrics:      &DebateMetrics{},
	}

	// Initialize Cognee client if enabled
	if cfg.EnableCognee && cfg.CogneeConfig != nil && cfg.CogneeConfig.Enabled {
		service.cogneeClient = &CogneeClient{
			config:  cfg.CogneeConfig,
			enabled: true,
			logger:  logger,
		}
	}

	// Initialize memory manager if enabled
	if cfg.EnableMemory {
		service.memoryManager = &DebateMemoryManager{
			maxContextLength: cfg.MaxContextLength,
			retentionTime:    time.Duration(cfg.MemoryRetention) * time.Millisecond,
			memoryStore:      make(map[string][]DebateMemory),
		}
	}

	// Initialize LLM providers for each participant
	if err := service.initializeProviders(); err != nil {
		return nil, fmt.Errorf("failed to initialize providers: %w", err)
	}

	return service, nil
}

// initializeProviders initializes LLM providers for all participants
func (s *AIDebateService) initializeProviders() error {
	for _, participantConfig := range s.config.Participants {
		if !participantConfig.Enabled {
			continue
		}

		// Find the primary LLM for this participant
		primaryLLM := participantConfig.GetPrimaryLLM()
		if primaryLLM == nil {
			return fmt.Errorf("participant %s has no enabled LLMs", participantConfig.Name)
		}

		// Create LLM provider based on the primary LLM configuration
		provider, err := s.createLLMProvider(primaryLLM)
		if err != nil {
			return fmt.Errorf("failed to create provider for participant %s: %w", participantConfig.Name, err)
		}

		s.llmProviders[participantConfig.Name] = provider
		s.logger.Infof("Initialized LLM provider for participant %s using %s (%s)",
			participantConfig.Name, primaryLLM.Name, primaryLLM.Model)
	}

	return nil
}

// createLLMProvider creates an LLM provider based on configuration
func (s *AIDebateService) createLLMProvider(llmConfig *config.LLMConfiguration) (llm.LLMProvider, error) {
	// This would integrate with the existing LLM provider system
	// For now, we'll create a basic implementation
	switch llmConfig.Provider {
	case "claude":
		return llm.NewClaudeProvider(llmConfig.APIKey, llmConfig.Model, llmConfig.BaseURL), nil
	case "deepseek":
		return llm.NewDeepSeekProvider(llmConfig.APIKey, llmConfig.Model, llmConfig.BaseURL), nil
	case "gemini":
		return llm.NewGeminiProvider(llmConfig.APIKey, llmConfig.Model, llmConfig.BaseURL), nil
	case "qwen":
		return llm.NewQwenProvider(llmConfig.APIKey, llmConfig.Model, llmConfig.BaseURL), nil
	case "zai":
		return llm.NewZaiProvider(llmConfig.APIKey, llmConfig.Model, llmConfig.BaseURL), nil
	case "ollama":
		return llm.NewOllamaProvider(llmConfig.BaseURL, llmConfig.Model), nil
	case "openrouter":
		return llm.NewOpenRouterProvider(llmConfig.APIKey), nil
	default:
		return nil, fmt.Errorf("unsupported provider: %s", llmConfig.Provider)
	}
}

// ConductDebate conducts an AI debate on the given topic
func (s *AIDebateService) ConductDebate(ctx context.Context, topic string, initialContext string) (*DebateResult, error) {
	if !s.config.Enabled {
		return nil, fmt.Errorf("AI debate service is disabled")
	}

	startTime := time.Now()
	sessionID := fmt.Sprintf("debate_%d", startTime.Unix())

	s.logger.Infof("Starting AI debate session %s on topic: %s", sessionID, topic)

	// Create debate session
	session := &DebateSession{
		ID:        sessionID,
		Topic:     topic,
		StartTime: startTime,
		Status:    "active",
	}

	// Initialize participants
	if err := s.initializeParticipants(session); err != nil {
		s.logger.Errorf("Failed to initialize participants: %v", err)
		return nil, fmt.Errorf("failed to initialize participants: %w", err)
	}

	// Conduct debate rounds
	result, err := s.conductDebateRounds(ctx, session, initialContext)
	if err != nil {
		session.Status = "failed"
		s.metrics.recordFailedDebate(time.Since(startTime))
		return nil, fmt.Errorf("debate failed: %w", err)
	}

	// Finalize session
	endTime := time.Now()
	session.Status = "completed"
	session.EndTime = &endTime
	session.FinalResult = result

	// Record metrics
	s.metrics.recordSuccessfulDebate(time.Since(startTime), result.Consensus != nil && result.Consensus.Reached)

	s.logger.Infof("Completed AI debate session %s in %v with consensus: %v",
		sessionID, result.Duration, result.Consensus != nil && result.Consensus.Reached)

	return result, nil
}

// initializeParticipants initializes all participants for the debate
func (s *AIDebateService) initializeParticipants(session *DebateSession) error {
	for _, participantConfig := range s.config.Participants {
		if !participantConfig.Enabled {
			continue
		}

		provider, exists := s.llmProviders[participantConfig.Name]
		if !exists {
			return fmt.Errorf("no provider found for participant %s", participantConfig.Name)
		}

		participant := DebateParticipant{
			Config:      &participantConfig,
			Provider:    provider,
			Score:       0.0,
			Reliability: 1.0,
		}

		session.Participants = append(session.Participants, participant)
	}

	if len(session.Participants) < 2 {
		return fmt.Errorf("at least 2 participants required for debate, got %d", len(session.Participants))
	}

	return nil
}

// conductDebateRounds conducts multiple rounds of debate
func (s *AIDebateService) conductDebateRounds(ctx context.Context, session *DebateSession, initialContext string) (*DebateResult, error) {
	maxRounds := s.config.MaximalRepeatRounds

	for round := 1; round <= maxRounds; round++ {
		s.logger.Infof("Conducting debate round %d for session %s", round, session.ID)

		debateRound := DebateRound{
			Number:    round,
			StartTime: time.Now(),
		}

		// Collect responses from all participants
		responses, err := s.collectParticipantResponses(ctx, session, &debateRound, initialContext)
		if err != nil {
			s.logger.Errorf("Failed to collect responses in round %d: %v", round, err)
			continue
		}

		debateRound.Responses = responses
		debateRound.EndTime = timePtr(time.Now())

		// Analyze consensus
		consensus := s.analyzeConsensus(responses, round)
		debateRound.Consensus = consensus
		session.Rounds = append(session.Rounds, debateRound)

		// Check if consensus is reached
		if consensus.Reached && consensus.ConsensusLevel >= s.config.ConsensusThreshold {
			s.logger.Infof("Consensus reached in round %d with level %f", round, consensus.ConsensusLevel)
			return s.createFinalResult(session, consensus, responses), nil
		}

		// Check if we should continue
		if round >= maxRounds {
			s.logger.Infof("Maximum rounds (%d) reached without consensus", maxRounds)
			break
		}

		// Prepare context for next round
		initialContext = s.prepareNextRoundContext(session, round)
	}

	// No consensus reached, create result from best available responses
	bestConsensus := s.analyzeConsensus(session.Rounds[len(session.Rounds)-1].Responses, maxRounds)
	return s.createFinalResult(session, bestConsensus, session.Rounds[len(session.Rounds)-1].Responses), nil
}

// collectParticipantResponses collects responses from all participants
func (s *AIDebateService) collectParticipantResponses(ctx context.Context, session *DebateSession, round *DebateRound, context string) ([]ParticipantResponse, error) {
	var responses []ParticipantResponse
	var mu sync.Mutex
	var wg sync.WaitGroup

	responseChan := make(chan ParticipantResponse, len(session.Participants))
	errorChan := make(chan error, len(session.Participants))

	for _, participant := range session.Participants {
		wg.Add(1)
		go func(p DebateParticipant) {
			defer wg.Done()

			response, err := s.getParticipantResponse(ctx, p, round.Number, context)
			if err != nil {
				s.logger.Errorf("Failed to get response from participant %s: %v", p.Config.Name, err)
				errorChan <- fmt.Errorf("participant %s: %w", p.Config.Name, err)
				return
			}

			responseChan <- response
		}(participant)
	}

	// Wait for all participants to respond or timeout
	done := make(chan bool)
	go func() {
		wg.Wait()
		done <- true
	}()

	select {
	case <-done:
		// All participants responded
	case <-time.After(time.Duration(s.config.MaxResponseTime) * time.Millisecond):
		s.logger.Warnf("Timeout waiting for participant responses in round %d", round.Number)
	}

	close(responseChan)
	close(errorChan)

	// Collect successful responses
	for response := range responseChan {
		mu.Lock()
		responses = append(responses, response)
		mu.Unlock()
	}

	// Check for errors
	var errors []error
	for err := range errorChan {
		errors = append(errors, err)
	}

	if len(responses) < 2 {
		return responses, fmt.Errorf("insufficient responses: got %d, need at least 2. Errors: %v", len(responses), errors)
	}

	return responses, nil
}

// getParticipantResponse gets a response from a single participant
func (s *AIDebateService) getParticipantResponse(ctx context.Context, participant DebateParticipant, roundNum int, context string) (ParticipantResponse, error) {
	startTime := time.Now()

	// Create LLM request
	request := &models.LLMRequest{
		Prompt: fmt.Sprintf("Debate Topic: %s\n\nContext: %s\n\nRound %d: Please provide your analysis and perspective.",
			participant.Config.Name, context, roundNum),
		ModelParams: models.ModelParameters{
			Temperature: participant.Config.LLMs[0].Temperature,
			MaxTokens:   participant.Config.LLMs[0].MaxTokens,
		},
		RequestType: "debate_participation",
	}

	// Add participant-specific context
	if s.memoryManager != nil {
		memoryContext := s.memoryManager.getRelevantMemory(participant.Config.Name, context)
		if memoryContext != "" {
			request.Prompt = fmt.Sprintf("Previous context: %s\n\n%s", memoryContext, request.Prompt)
		}
	}

	// Call LLM provider
	response, err := participant.Provider.Complete(request)
	if err != nil {
		return ParticipantResponse{}, fmt.Errorf("LLM completion failed: %w", err)
	}

	responseTime := time.Since(startTime)

	// Create participant response
	participantResponse := ParticipantResponse{
		ParticipantName: participant.Config.Name,
		LLMName:         participant.Config.LLMs[0].Name,
		Content:         response.Content,
		Confidence:      response.Confidence,
		QualityScore:    response.SelectionScore,
		ResponseTime:    responseTime,
		RoundNumber:     roundNum,
		Timestamp:       startTime,
		CogneeEnhanced:  false,
		Metadata:        response.Metadata,
	}

	// Enhance with Cognee if enabled
	if s.cogneeClient != nil && s.cogneeClient.enabled && participant.Config.EnableCognee {
		enhancedResponse, err := s.cogneeClient.enhanceResponse(participantResponse, participant.Config)
		if err != nil {
			s.logger.Warnf("Failed to enhance response with Cognee: %v", err)
		} else {
			participantResponse = enhancedResponse
		}
	}

	return participantResponse, nil
}

// analyzeConsensus analyzes the consensus level among participant responses
func (s *AIDebateService) analyzeConsensus(responses []ParticipantResponse, roundNum int) *ConsensusResult {
	if len(responses) == 0 {
		return &ConsensusResult{
			Reached:        false,
			ConsensusLevel: 0.0,
			AgreementScore: 0.0,
			QualityScore:   0.0,
			Summary:        "No responses available for consensus analysis",
		}
	}

	// Calculate average confidence and quality scores
	avgConfidence := 0.0
	avgQuality := 0.0
	for _, response := range responses {
		avgConfidence += response.Confidence
		avgQuality += response.QualityScore
	}
	avgConfidence /= float64(len(responses))
	avgQuality /= float64(len(responses))

	// Simple consensus calculation based on confidence and quality
	consensusLevel := (avgConfidence + avgQuality) / 2.0

	// Determine if consensus is reached
	consensusReached := consensusLevel >= s.config.ConsensusThreshold

	// Generate summary (simplified for this implementation)
	summary := fmt.Sprintf("Round %d: %d participants responded with average confidence %.2f and quality %.2f",
		roundNum, len(responses), avgConfidence, avgQuality)

	result := &ConsensusResult{
		Reached:        consensusReached,
		ConsensusLevel: consensusLevel,
		AgreementScore: avgConfidence,
		QualityScore:   avgQuality,
		Summary:        summary,
		KeyPoints:      s.extractKeyPoints(responses),
	}

	// Enhance with Cognee if enabled
	if s.cogneeClient != nil && s.cogneeClient.enabled && s.config.CogneeConfig.AnalyzeConsensus {
		cogneeInsights, err := s.cogneeClient.analyzeConsensus(responses)
		if err != nil {
			s.logger.Warnf("Failed to analyze consensus with Cognee: %v", err)
		} else {
			result.CogneeInsights = cogneeInsights
		}
	}

	return result
}

// extractKeyPoints extracts key points from participant responses
func (s *AIDebateService) extractKeyPoints(responses []ParticipantResponse) []string {
	// Simplified implementation - in a real system, this would use NLP techniques
	var keyPoints []string
	pointMap := make(map[string]int)

	for _, response := range responses {
		// Simple keyword extraction (would be more sophisticated in production)
		words := extractKeywords(response.Content)
		for _, word := range words {
			pointMap[word]++
		}
	}

	// Get most frequent points
	for point, count := range pointMap {
		if count >= len(responses)/2 { // Point mentioned by at least half
			keyPoints = append(keyPoints, point)
		}
	}

	return keyPoints
}

// prepareNextRoundContext prepares context for the next debate round
func (s *AIDebateService) prepareNextRoundContext(session *DebateSession, currentRound int) string {
	if len(session.Rounds) == 0 {
		return ""
	}

	lastRound := session.Rounds[len(session.Rounds)-1]

	context := fmt.Sprintf("Previous round summary: %s\n\n", lastRound.Consensus.Summary)

	// Add key disagreements or points of contention
	if len(lastRound.Consensus.Disagreements) > 0 {
		context += "Key points of disagreement:\n"
		for _, disagreement := range lastRound.Consensus.Disagreements {
			context += fmt.Sprintf("- %s\n", disagreement)
		}
		context += "\n"
	}

	// Add memory context if available
	if s.memoryManager != nil {
		memoryContext := s.memoryManager.getRelevantMemory("all", context)
		if memoryContext != "" {
			context = fmt.Sprintf("Relevant previous context: %s\n\n%s", memoryContext, context)
		}
	}

	return context
}

// createFinalResult creates the final debate result
func (s *AIDebateService) createFinalResult(session *DebateSession, consensus *ConsensusResult, responses []ParticipantResponse) *DebateResult {
	duration := time.Since(session.StartTime)

	// Find best response (highest confidence + quality)
	bestResponse := responses[0]
	bestScore := bestResponse.Confidence + bestResponse.QualityScore

	for _, response := range responses[1:] {
		score := response.Confidence + response.QualityScore
		if score > bestScore {
			bestScore = score
			bestResponse = response
		}
	}

	// Calculate quality metrics
	qualityMetrics := make(map[string]float64)
	qualityMetrics["avg_confidence"] = 0.0
	qualityMetrics["avg_quality"] = 0.0
	qualityMetrics["response_time_avg"] = 0.0

	for _, response := range responses {
		qualityMetrics["avg_confidence"] += response.Confidence
		qualityMetrics["avg_quality"] += response.QualityScore
		qualityMetrics["response_time_avg"] += float64(response.ResponseTime.Milliseconds())
	}

	qualityMetrics["avg_confidence"] /= float64(len(responses))
	qualityMetrics["avg_quality"] /= float64(len(responses))
	qualityMetrics["response_time_avg"] /= float64(len(responses))

	// Generate recommendations
	recommendations := s.generateRecommendations(consensus, responses)

	return &DebateResult{
		SessionID:       session.ID,
		Topic:           session.Topic,
		Consensus:       consensus,
		BestResponse:    bestResponse,
		AllResponses:    responses,
		Duration:        duration,
		RoundsConducted: len(session.Rounds),
		FinalScore:      bestScore,
		QualityMetrics:  qualityMetrics,
		Recommendations: recommendations,
	}
}

// generateRecommendations generates recommendations based on the debate result
func (s *AIDebateService) generateRecommendations(consensus *ConsensusResult, responses []ParticipantResponse) []string {
	var recommendations []string

	if consensus.Reached {
		recommendations = append(recommendations, "Consensus was successfully reached among participants.")
	} else {
		recommendations = append(recommendations, "Consider providing more context or clarifying the topic for better consensus.")
	}

	if consensus.QualityScore < 0.7 {
		recommendations = append(recommendations, "Quality scores were below optimal. Consider adjusting participant parameters.")
	}

	if len(responses) < 3 {
		recommendations = append(recommendations, "Limited participant responses. Consider adding more participants for diverse perspectives.")
	}

	return recommendations
}

// Metrics methods
func (m *DebateMetrics) recordSuccessfulDebate(duration time.Duration, consensusReached bool) {
	m.mu.Lock()
	defer m.mu.Unlock()

	m.TotalDebates++
	m.SuccessfulDebates++
	m.AverageDuration = (m.AverageDuration + duration) / 2 // Simplified average calculation
	if consensusReached {
		m.ConsensusReached++
	}
}

func (m *DebateMetrics) recordFailedDebate(duration time.Duration) {
	m.mu.Lock()
	defer m.mu.Unlock()

	m.TotalDebates++
	m.FailedDebates++
	m.AverageDuration = (m.AverageDuration + duration) / 2
}

// CogneeClient methods
func (c *CogneeClient) enhanceResponse(response ParticipantResponse, participantConfig *config.DebateParticipant) (ParticipantResponse, error) {
	if !c.enabled {
		return response, nil
	}

	// This would integrate with the actual Cognee AI system
	// For now, we'll simulate enhancement
	c.logger.Debugf("Enhancing response from %s with Cognee", response.ParticipantName)

	// Simulate Cognee enhancement
	enhancedResponse := response
	enhancedResponse.Content = fmt.Sprintf("[Cognee Enhanced] %s", response.Content)
	enhancedResponse.Confidence = min(response.Confidence*1.1, 1.0) // Boost confidence slightly
	enhancedResponse.CogneeEnhanced = true

	return enhancedResponse, nil
}

func (c *CogneeClient) analyzeConsensus(responses []ParticipantResponse) (*CogneeInsights, error) {
	if !c.enabled {
		return nil, nil
	}

	c.logger.Debug("Analyzing consensus with Cognee")

	// This would integrate with the actual Cognee AI system
	// For now, we'll simulate analysis
	insights := &CogneeInsights{
		SentimentAnalysis: make(map[string]float64),
		EntityExtraction:  []string{"AI", "debate", "consensus"},
		TopicModeling:     []string{"artificial intelligence", "collaborative analysis"},
		CoherenceScore:    0.75,
		RelevanceScore:    0.80,
		InnovationScore:   0.65,
		Summary:           "Cognee analysis indicates moderate consensus with diverse perspectives",
	}

	return insights, nil
}

// DebateMemoryManager methods
func (m *DebateMemoryManager) getRelevantMemory(participantName, context string) string {
	if m == nil {
		return ""
	}

	m.mu.RLock()
	defer m.mu.RUnlock()

	memories, exists := m.memoryStore[participantName]
	if !exists {
		return ""
	}

	// Find most relevant memory (simplified implementation)
	var bestMemory DebateMemory
	bestRelevance := 0.0

	for _, memory := range memories {
		// Simple relevance check - would be more sophisticated in production
		if memory.Relevance > bestRelevance && time.Since(memory.Timestamp) < m.retentionTime {
			bestRelevance = memory.Relevance
			bestMemory = memory
		}
	}

	if bestRelevance > 0.5 { // Threshold for relevance
		return bestMemory.Content
	}

	return ""
}

func (m *DebateMemoryManager) storeMemory(memory DebateMemory) {
	if m == nil {
		return
	}

	m.mu.Lock()
	defer m.mu.Unlock()

	if m.memoryStore[memory.Participant] == nil {
		m.memoryStore[memory.Participant] = []DebateMemory{}
	}

	m.memoryStore[memory.Participant] = append(m.memoryStore[memory.Participant], memory)

	// Clean up old memories
	m.cleanupOldMemories()
}

func (m *DebateMemoryManager) cleanupOldMemories() {
	cutoff := time.Now().Add(-m.retentionTime)

	for participant, memories := range m.memoryStore {
		var validMemories []DebateMemory
		for _, memory := range memories {
			if memory.Timestamp.After(cutoff) {
				validMemories = append(validMemories, memory)
			}
		}
		m.memoryStore[participant] = validMemories
	}
}

// Helper functions
func timePtr(t time.Time) *time.Time {
	return &t
}

func min(a, b float64) float64 {
	if a < b {
		return a
	}
	return b
}

func extractKeywords(text string) []string {
	// Simplified keyword extraction - would use proper NLP in production
	// For now, just return some common words
	return []string{"analysis", "solution", "approach", "method", "result"}
}
