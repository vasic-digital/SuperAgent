Yes, there are many free and open-source Model Context Protocol (MCP) servers that connect LLMs to tools for design, UI, image generation, asset creation, and more. Most are freely available to install and use, though some may require API keys for external services or access to specific local software.

---

ğŸ¨ Design & UI Integration

These servers bridge LLMs with popular design tools.

Server Description Requirements Source
Cursor Talk to Figma MCP Read and modify Figma designs using natural language. No explicit API keys needed. Requires Figma plugin and Cursor (or other MCP client).
Framelink Figma MCP Server Fetches and simplifies Figma file data for AI coding tools. Figma API access token.
Figma MCP Server with Chunking Handles large Figma files efficiently with chunking/pagination. Figma API access token.
MCP Figma to React Converter Converts Figma designs directly into React components. Figma API token.
Illustrator MCP Server Allows AI assistants to interact with Adobe Illustrator via JavaScript. macOS + Adobe Illustrator.
MCPâ€‘Miro Connects to Miro whiteboards for creating sticky notes, shapes, etc. Miro OAuth token.
Photoshop Python API MCP Server Provides programmatic control of Adobe Photoshop. No specific API keys for basic setup.

---

ğŸ–¼ï¸ Image Generation & Editing

Servers that generate or manipulate images.

Server Description Requirements Source
Image Generation MCP Server (Replicate Flux) Generates images using the Replicate Flux model. Replicate API token (free tier available).
FLUX Image Generator Uses Black Forest Labâ€™s FLUX model for text-to-image generation. Black Forest Lab API key.
Stable Diffusion MCP Server Connects to a local Stable Diffusion WebUI for private, GPUâ€‘accelerated image generation. Local Stable Diffusion WebUI setup.
ImageSorcery MCP Provides local imageâ€‘processing tools (crop, resize, OCR, object detection). Python 3.10+; downloads models locally.

---

ğŸ› ï¸ Asset Creation & Vector Graphics

Tools for generating and editing vector assets.

Server Description Requirements Source
SVGMaker MCP AIâ€‘powered SVG generation, editing, and imageâ€‘toâ€‘SVG conversion. SVGMaker API key (free tier likely).

---

ğŸ§° Multiâ€‘Purpose Toolboxes

Servers that bundle many capabilities into one.

Server Description Requirements Source
MCPâ€‘Toolbox A comprehensive collection of tools for Figma, audio, memory, web search, and image generation (via Flux). Various API keys (Figma, Tavily, DuckDuckGo, BFL) depending on which tools you use.

---

ğŸ’¡ How to Get Started

1. Choose an MCP client: Popular options include Claude Desktop, Cursor, Windsurf, or Cline.
2. Install the server: Most servers can be installed via npm, pip, or by cloning their GitHub repository.
3. Configure your client: Add the server configuration to your clientâ€™s config file (e.g., claude_desktop_config.json).
4. Set up required access: For servers that need API keys, obtain the relevant token (many services offer free tiers).

Note on â€œfreeâ€: The MCP servers themselves are openâ€‘source and free to use. However, some rely on external APIs (e.g., Replicate, Black Forest Lab, Figma, SVGMaker) that may have usage limits or costs beyond a free tier. Local servers (like Stable Diffusion MCP or ImageSorcery) run entirely on your hardware and incur no extra charges.

---

ğŸ”— Useful Resources

Â· Awesome MCP Servers: A curated list of MCP servers.
Â· 14 MCP Servers for UI/UX Engineers (Snyk article): Detailed overview of designâ€‘focused servers.
Â· MCP Servers registry: Browse servers by category.

By mixing and matching these free MCP servers, you can equip your LLM with a powerful suite of design, UI, image, and assetâ€‘generation capabilities. Start with the servers that match your immediate needs (e.g., Figma integration for design, Stable Diffusion for local image generation) and expand your toolkit as your workflows evolve.

Main resources online:

https://mcpservers.org/all

https://snyk.io/articles/14-mcp-servers-for-ui-ux-engineers/

https://mcpservers.org/remote-mcp-servers

Next:

Here are free, open-source MCP servers, LSP servers, and embedding models you can integrate with your LLMs and AI CLI coding agents (like Google Gemini CLI, Aider, or Claude Code).

ğŸ› ï¸ Free MCP Servers

Model Context Protocol (MCP) servers let your AI agents access tools and data. The following are free and open-source, though some may require an API key for external services.

Server Description License / Cost Source
Filesystem Secure file operations with configurable access controls. Openâ€‘source (free) Reference servers
Git Tools to read, search, and manipulate Git repositories. Openâ€‘source (free) Reference servers
Fetch Webâ€‘content fetching and conversion for efficient LLM usage. Openâ€‘source (free) Reference servers
Memory Knowledgeâ€‘graphâ€‘based persistent memory system. Openâ€‘source (free) Reference servers
Time Time and timezone conversion capabilities. Openâ€‘source (free) Reference servers
Chroma Embeddings, vector search, document storage, and fullâ€‘text search. Openâ€‘source (free) Awesome MCP Servers
Qdrant MCP Vector Server Vectorâ€‘search server for similarity retrieval. Openâ€‘source (free) Awesome MCP Servers
AWS Bedrock KB Retrieval Query Amazon Bedrock Knowledge Bases using natural language. Requires AWS account (payâ€‘perâ€‘use) Awesome MCP Servers

How to use: Add the serverâ€™s configuration to your CLI agentâ€™s config file (e.g., claude_desktop_config.json). Many servers are available via npm or pip.

ğŸ’» Free LSP Servers for AI Coding Agents

Language Server Protocol (LSP) servers provide code intelligence (completion, diagnostics, etc.). These can be used by AI coding agents to understand code structure.

Server Description License / Cost Source
LSPâ€‘AI Openâ€‘source language server that serves as a backend for AIâ€‘powered functionality; supports inâ€‘editor chatting, code completions, and works with any LSPâ€‘compatible editor. Openâ€‘source (free) GitHub â€“ SilasMarvin/lspâ€‘ai
clangd Official LSP server for C/C++. Openâ€‘source (free) clangd.llvm.org
pylsp Official LSP server for Python (formerly pythonâ€‘languageâ€‘server). Openâ€‘source (free) GitHub â€“ pythonâ€‘lsp/pythonâ€‘lspâ€‘server
typescriptâ€‘languageâ€‘server LSP server for TypeScript/JavaScript. Openâ€‘source (free) GitHub â€“ typescriptâ€‘languageâ€‘server
rustâ€‘analyzer LSP server for Rust. Openâ€‘source (free) GitHub â€“ rustâ€‘analyzer
sumnekoâ€‘luaâ€‘languageâ€‘server LSP server for Lua. Openâ€‘source (free) GitHub â€“ sumneko/luaâ€‘languageâ€‘server

How to use: Install the LSP server locally and configure your editor or AI agent to connect to it. LSPâ€‘AI is particularly designed for AI integration and supports multiple LLM backends (llama.cpp, Ollama, OpenAIâ€‘compatible APIs, etc.).

ğŸ”¤ Free Embedding Models

Embedding models convert text into vectors for semantic search, retrievalâ€‘augmented generation (RAG), and other LLM tasks. The following are openâ€‘source and can be run locally or via hosted APIs (some with free tiers).

Model Description License / Cost Source
Qwen3â€‘Embeddingâ€‘0.6B Multilingual, instructionâ€‘aware, flexible output dimensions (32â€‘1024). Apache 2.0 (free) Hugging Face
EmbeddingGemmaâ€‘300M Lightweight, multilingual, optimized for onâ€‘device deployment. Apache 2.0 (free) Hugging Face
Jina Embeddings v4 Universal, multimodal, multilingual (dense & multiâ€‘vector). CCâ€‘BYâ€‘NCâ€‘4.0 (nonâ€‘commercial) Jina AI
BGEâ€‘M3 Multiâ€‘functionality (dense, multiâ€‘vector, sparse), multilingual, longâ€‘context (8192 tokens). MIT (free) Hugging Face
allâ€‘mpnetâ€‘baseâ€‘v2 Sentenceâ€‘transformer model, good for English sentences/paragraphs. MIT (free) Hugging Face
gteâ€‘multilingualâ€‘base Generalâ€‘purpose multilingual embedding model. MIT (free) Hugging Face
Nomic Embed Text V2 Matryoshkaâ€‘style embeddings, adjustable dimensionality. Apache 2.0 (free) Hugging Face

How to use: Run locally with libraries like sentenceâ€‘transformers, transformers, or via Ollama. For vector storage, pair with local databases (Chroma, FAISS, Qdrant) or use an MCP server like Chroma or Qdrant MCP Vector Server.

ğŸ“ Integration Summary

1. MCP servers extend your CLI agent with tools (files, Git, web, vectors, etc.). Start with the reference servers (Filesystem, Git, Fetch) for basic operations.
2. LSP servers give your agent deep code understanding. LSPâ€‘AI is built for AI integration, while traditional LSPs (clangd, pylsp) provide languageâ€‘specific intelligence.
3. Embedding models enable semantic search and RAG. Choose based on language, size, and performance needs; run them locally or via freeâ€‘tier APIs.

For a completely free stack, combine Google Gemini CLI (generous free tier) with Filesystem, Git, and Chroma MCP servers, use LSPâ€‘AI for code intelligence, and run BGEâ€‘M3 or allâ€‘mpnetâ€‘baseâ€‘v2 locally for embeddings.

If you have a specific use case (e.g., â€œI need to search my codebaseâ€ or â€œI want to generate imagesâ€), let me know and I can recommend more targeted servers.

Integrating Language Server Protocol (LSP) servers with your LLMs and AI CLI agents can significantly enhance their code intelligence, enabling features like deep semantic understanding, autocompletion, and precise refactoring. Below is a comprehensive overview of free, open-source LSP servers and related tools suitable for AI workflows.

ğŸ§  AIâ€‘Specific LSP Servers

These servers are built with AI integration as a primary goal, often acting as a bridge between traditional LSP features and LLM backends.

Server Description Key Features for AI License / Cost
LSPâ€‘AI An openâ€‘source language server that serves as a backend for AIâ€‘powered functionality in editors. It abstracts LLM integration and provides inâ€‘editor chat, custom actions, and code completions. â€“ Supports llama.cpp, Ollama, OpenAIâ€‘compatible, Anthropicâ€‘compatible, Geminiâ€‘compatible, and Mistral AI FIMâ€‘compatible APIs. â€“ Works with any editor that supports LSP (VS Code, NeoVim, Emacs, Helix, etc.). â€“ Provides structured context for AI agents. MIT (free)
OpenCode An openâ€‘source AI coding agent that automatically loads the appropriate LSPs for the LLM being used. It operates in terminal, IDE, or desktop environments. â€“ â€œLSP enabled: Automatically loads the right LSPs for the LLMâ€. â€“ Supports 75+ LLM providers, including local models. â€“ Multiâ€‘session and privacyâ€‘focused (no code storage). Openâ€‘source (free)

ğŸ“š Traditional LSP Servers (by Language)

These are standard, languageâ€‘specific LSP servers that provide deep semantic understanding (goâ€‘toâ€‘definition, find references, etc.). Most are free and openâ€‘source.

Language Recommended Server(s) Notes
Python pyright (Microsoft), palantir (Python LSP Server) Both are widely used; pyright is faster, palantir is more extensible.
JavaScript/TypeScript typescriptâ€‘languageâ€‘server (official), deno lsp (Deno) The TypeScript server is the standard; Denoâ€™s LSP also supports TS/JS.
C/C++ clangd (LLVM), ccls, cquery clangd is the most active and recommended.
Rust rustâ€‘analyzer The deâ€‘facto standard for Rust.
Go gopls (Go team) Official Go language server.
Java eclipseâ€‘jdtâ€‘ls (Eclipse), javaâ€‘languageâ€‘server (Red Hat) Eclipse JDT LS is the most fullâ€‘featured.
C# omnisharpâ€‘roslyn, csharpâ€‘ls OmniSharp is the traditional choice; csharpâ€‘ls is a newer alternative.
PHP phpactor (PHPactor), intelephense (proprietary) PHPactor is openâ€‘source; Intelephense has a free tier with limitations.
Ruby solargraph Standard Ruby LSP.
Elixir elixirâ€‘ls Official Elixir LSP.
Haskell haskellâ€‘languageâ€‘server (HLS) The main Haskell server.
Shell (Bash) bashâ€‘languageâ€‘server Provides linting, formatting, and completions.
Dockerfile dockerâ€‘languageâ€‘server Supports Dockerfile syntax.
YAML yamlâ€‘languageâ€‘server Provides schema validation, completion.
XML lemminx The standard XML LSP.
Terraform terraformâ€‘ls (Hashicorp) Official Terraform LSP.

Sources: The above list is curated from the â€œAwesome LSP Serversâ€ GitHub repository and the official Microsoft LSP Implementations page.

ğŸ”Œ MCP Servers with LSPâ€‘Like Capabilities

These Model Context Protocol (MCP) servers expose codeâ€‘analysis tools to AI agents, often in a lighterâ€‘weight, more secure manner than a full LSP server.

Server Description Use Case for AI Agents License
LSP Tools MCP Server A lightweight Node.js MCP server that provides regexâ€‘based textâ€‘search and directoryâ€‘listing tools. It is designed for â€œsurgical precisionâ€ in textâ€‘based tasks. â€“ Finding exact pattern matches in code (e.g., for auditing, refactoring prep). â€“ Securityâ€‘focused: only accesses explicitly allowed directories. MIT (free)
Neovim LSP MCP Server (mentioned in search results) An MCP server that bridges AI coding assistants with Neovimâ€™s LSP capabilities. Allows AI agents to leverage Neovimâ€™s builtâ€‘in LSP client for code navigation, definition lookup, etc. Likely openâ€‘source
Semantic Analysis MCP Servers (e.g., isaacphi/mcpâ€‘languageâ€‘server, Tritlo/lspâ€‘mcp) Full bridges to the Language Server Protocol, providing deep semantic tools (find all references, get definition, rename symbol). When your AI agent needs true languageâ€‘aware code intelligence, not just text search. Varies (often MIT)

ğŸ› ï¸ How to Integrate These LSPs with Your AI CLI Agents

Integration generally follows two paths:

1. Direct LSP Integration: Some AI CLI agents (like OpenCode) have builtâ€‘in LSP support and automatically load relevant servers. For custom agents, you can use an LSP client library (e.g., lspâ€‘client in Node.js, pythonâ€‘lspâ€‘client) to communicate with the LSP server over JSONâ€‘RPC.
2. Via MCP (Model Context Protocol): Many modern AI CLI agents (e.g., Claude Code, Google Gemini CLI, Cursor) support MCP. To add an LSPâ€‘like tool:
   Â· Install the MCP server (e.g., lspâ€‘toolsâ€‘mcp).
   Â· Add its configuration to your agentâ€™s MCP settings file (e.g., claude_desktop_config.json).
   Â· The agent will then discover the serverâ€™s tools (e.g., find_regex_position) and use them in its workflow.

ğŸ’¡ Recommendations for Different Workflows

Â· For AIâ€‘centric coding assistants: Start with LSPâ€‘AIâ€”itâ€™s designed specifically to bring LLMâ€‘powered features (chat, completions, refactoring) into any LSPâ€‘compatible editor.
Â· For languageâ€‘specific deep code intelligence: Use the traditional LSP servers listed above. They provide the most accurate semantic understanding for each language.
Â· For lightweight, secure code analysis in AI agents: The LSP Tools MCP Server is ideal for regexâ€‘based search tasks without the overhead of a full LSP.
Â· For an allâ€‘inâ€‘one AI coding agent with builtâ€‘in LSP support: OpenCode automatically manages LSPs for you, making it a good â€œbatteriesâ€‘includedâ€ option.

Note on â€œfreeâ€: The servers listed here are openâ€‘source and free to use. However, some (like LSPâ€‘AI) require you to bring your own LLM backend (which may have associated costs). Traditional LSP servers are typically completely free and do not require any external API.

For a more exhaustive list of LSP servers, you can browse the Microsoft LSP Implementations page or the Awesome LSP Servers repository.

If you have a specific language or use case in mind (e.g., â€œI need an LSP for Go that works well with AI refactoringâ€), I can help narrow down the options further.

Main resources:

https://microsoft.github.io/language-server-protocol/implementors/servers/

https://github.com/Hexlet/awesome-lsp-servers
