version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: superagent-postgres
    environment:
      POSTGRES_DB: ${DB_NAME:-superagent_db}
      POSTGRES_USER: ${DB_USER:-superagent}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-superagent123}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8"
    ports:
      - "${DB_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    networks:
      - superagent-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-superagent} -d ${DB_NAME:-superagent_db}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Redis Cache
  redis:
    image: redis:7-alpine
    container_name: superagent-redis
    command: redis-server --requirepass ${REDIS_PASSWORD:-superagent123} --appendonly yes
    ports:
      - "${REDIS_PORT:-6379}:6379"
    volumes:
      - redis_data:/data
    networks:
      - superagent-network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Ollama for local LLM testing (free, no API keys needed)
  ollama:
    image: ollama/ollama:latest
    container_name: superagent-ollama
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - superagent-network
    environment:
      - OLLAMA_HOST=0.0.0.0
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    profiles:
      - ai
      - full

  # SuperAgent Application
  superagent:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: superagent-app
    ports:
      - "${PORT:-8080}:8080"
    environment:
      # Server Configuration
      PORT: ${PORT:-8080}
      SUPERAGENT_API_KEY: ${SUPERAGENT_API_KEY:-development-key}
      GIN_MODE: ${GIN_MODE:-release}

      # JWT Configuration
      JWT_SECRET: ${JWT_SECRET:-development-jwt-secret-key-change-in-production}
      TOKEN_EXPIRY: ${TOKEN_EXPIRY:-24h}

      # Database Configuration
      DB_HOST: ${DB_HOST:-postgres}
      DB_PORT: ${DB_PORT:-5432}
      DB_USER: ${DB_USER:-superagent}
      DB_PASSWORD: ${DB_PASSWORD:-superagent123}
      DB_NAME: ${DB_NAME:-superagent_db}
      DB_SSLMODE: ${DB_SSLMODE:-disable}

      # Redis Configuration
      REDIS_HOST: ${REDIS_HOST:-redis}
      REDIS_PORT: ${REDIS_PORT:-6379}
      REDIS_PASSWORD: ${REDIS_PASSWORD:-superagent123}
      REDIS_DB: ${REDIS_DB:-0}

      # LLM Provider API Keys (optional for production)
      CLAUDE_API_KEY: ${CLAUDE_API_KEY:-}
      DEEPSEEK_API_KEY: ${DEEPSEEK_API_KEY:-}
      GEMINI_API_KEY: ${GEMINI_API_KEY:-}
      QWEN_API_KEY: ${QWEN_API_KEY:-}
      ZAI_API_KEY: ${ZAI_API_KEY:-}

      # Ollama Configuration (free, no API keys needed)
      OLLAMA_BASE_URL: ${OLLAMA_BASE_URL:-http://ollama:11434}
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama2}
      OLLAMA_ENABLED: ${OLLAMA_ENABLED:-true}

      # Cognee Configuration
      COGNEE_BASE_URL: ${COGNEE_BASE_URL:-http://cognee:8000}
      COGNEE_API_KEY: ${COGNEE_API_KEY:-}
      COGNEE_AUTO_COGNIFY: ${COGNEE_AUTO_COGNIFY:-true}

      # Plugin Configuration
      PLUGIN_WATCH_PATHS: ${PLUGIN_WATCH_PATHS:-/app/plugins}
      PLUGIN_AUTO_RELOAD: ${PLUGIN_AUTO_RELOAD:-false}

      # Models.dev Configuration
      MODELSDEV_ENABLED: ${MODELSDEV_ENABLED:-false}
      MODELSDEV_API_KEY: ${MODELSDEV_API_KEY:-}
      MODELSDEV_BASE_URL: ${MODELSDEV_BASE_URL:-https://api.models.dev/v1}
      MODELSDEV_REFRESH_INTERVAL: ${MODELSDEV_REFRESH_INTERVAL:-24h}
      MODELSDEV_CACHE_TTL: ${MODELSDEV_CACHE_TTL:-1h}
      MODELSDEV_BATCH_SIZE: ${MODELSDEV_BATCH_SIZE:-100}
      MODELSDEV_MAX_RETRIES: ${MODELSDEV_MAX_RETRIES:-3}
      MODELSDEV_AUTO_REFRESH: ${MODELSDEV_AUTO_REFRESH:-true}
      MODELSDEV_TIMEOUT: ${MODELSDEV_TIMEOUT:-30}
      MODELSDEV_USER_AGENT: ${MODELSDEV_USER_AGENT:-SuperAgent/1.0}
      MODELSDEV_RATE_LIMIT: ${MODELSDEV_RATE_LIMIT:-10}

      # Rate Limiting
      RATE_LIMIT_REQUESTS: ${RATE_LIMIT_REQUESTS:-100}
      RATE_LIMIT_WINDOW: ${RATE_LIMIT_WINDOW:-1m}

      # Monitoring
      METRICS_ENABLED: ${METRICS_ENABLED:-true}
      LOG_LEVEL: ${LOG_LEVEL:-info}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./plugins:/app/plugins
      - ./logs:/app/logs
    networks:
      - superagent-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Prometheus Monitoring
  prometheus:
    image: prom/prometheus:latest
    container_name: superagent-prometheus
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    networks:
      - superagent-network
    restart: unless-stopped
    profiles:
      - monitoring
      - full

  # Grafana Dashboard
  grafana:
    image: grafana/grafana:latest
    container_name: superagent-grafana
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin123}
      GF_USERS_ALLOW_SIGN_UP: ${GRAFANA_ALLOW_SIGNUP:-false}
      GF_INSTALL_PLUGINS: ${GRAFANA_PLUGINS:-}
    ports:
      - "${GRAFANA_PORT:-3000}:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./docs/monitoring/grafana-dashboard.json:/etc/grafana/provisioning/dashboards/superagent.json
      - ./monitoring/grafana-datasources.yml:/etc/grafana/provisioning/datasources/datasources.yml
      - ./monitoring/grafana-dashboards.yml:/etc/grafana/provisioning/dashboards/dashboards.yml
    networks:
      - superagent-network
    depends_on:
      - prometheus
    restart: unless-stopped
    profiles:
      - monitoring
      - full

  # Cognee Knowledge Graph Service - Full-featured AI Memory Engine
  # Provides: Memory, Knowledge Graphs, Vector Search, Temporal Awareness, Code Intelligence
  cognee:
    image: cognee/cognee:main
    container_name: superagent-cognee
    ports:
      - "${COGNEE_PORT:-8000}:8000"
    environment:
      # Core Configuration
      - DEBUG=${COGNEE_DEBUG:-false}
      - HOST=0.0.0.0
      - PORT=8000
      - ENVIRONMENT=${COGNEE_ENVIRONMENT:-production}
      - LOG_LEVEL=${COGNEE_LOG_LEVEL:-INFO}

      # LLM Configuration for Cognee's internal processing
      - LLM_API_KEY=${LLM_API_KEY:-}
      - LLM_PROVIDER=${COGNEE_LLM_PROVIDER:-openai}
      - LLM_MODEL=${COGNEE_LLM_MODEL:-gpt-4o-mini}

      # Three-Tier Storage Architecture
      # Graph Database - NetworkX (default) or Neo4j/Memgraph for production
      - GRAPH_DATABASE=${COGNEE_GRAPH_DATABASE:-networkx}
      - GRAPH_DATABASE_URL=${COGNEE_GRAPH_DATABASE_URL:-}
      - GRAPH_DATABASE_USERNAME=${COGNEE_GRAPH_USERNAME:-neo4j}
      - GRAPH_DATABASE_PASSWORD=${COGNEE_GRAPH_PASSWORD:-cognee123}

      # Vector Database - ChromaDB for embeddings
      - VECTOR_DATABASE=${COGNEE_VECTOR_DATABASE:-chromadb}
      - VECTOR_DATABASE_URL=http://chromadb:8000
      - VECTOR_DB_KEY=${VECTOR_DB_KEY:-cognee_vector_key}

      # Relational Database - PostgreSQL with pgvector
      - RELATIONAL_DATABASE=postgresql
      - RELATIONAL_DATABASE_URL=postgresql://${DB_USER:-superagent}:${DB_PASSWORD:-superagent123}@postgres:5432/${DB_NAME:-superagent_db}

      # Cache Provider - Redis for performance
      - CACHE_PROVIDER=redis
      - CACHE_URL=redis://:${REDIS_PASSWORD:-superagent123}@redis:6379/0

      # Cognee Feature Flags - ALL ENABLED for maximum capability
      - COGNEE_ENABLE_TEMPORAL=true
      - COGNEE_ENABLE_FEEDBACK=true
      - COGNEE_ENABLE_CODE_PIPELINE=true
      - COGNEE_ENABLE_GRAPH_REASONING=true
      - COGNEE_ENABLE_AUTO_COGNIFY=true
      - COGNEE_ENABLE_MULTI_HOP=true
      - COGNEE_ENABLE_ENTITY_EXTRACTION=true
      - COGNEE_ENABLE_RELATIONSHIP_INFERENCE=true

      # Performance Optimization
      - COGNEE_BATCH_SIZE=${COGNEE_BATCH_SIZE:-50}
      - COGNEE_MAX_CONCURRENT=${COGNEE_MAX_CONCURRENT:-10}
      - COGNEE_CHUNK_SIZE=${COGNEE_CHUNK_SIZE:-1024}
      - COGNEE_OVERLAP_SIZE=${COGNEE_OVERLAP_SIZE:-128}
      - COGNEE_EMBEDDING_BATCH_SIZE=${COGNEE_EMBEDDING_BATCH_SIZE:-32}

      # Memory Configuration
      - COGNEE_MAX_MEMORY_SIZE=${COGNEE_MAX_MEMORY_SIZE:-10000}
      - COGNEE_MEMORY_TTL=${COGNEE_MEMORY_TTL:-0}
      - COGNEE_MEMORY_COMPRESSION=${COGNEE_MEMORY_COMPRESSION:-true}

      # Search Configuration
      - COGNEE_DEFAULT_SEARCH_LIMIT=${COGNEE_DEFAULT_SEARCH_LIMIT:-10}
      - COGNEE_RELEVANCE_THRESHOLD=${COGNEE_RELEVANCE_THRESHOLD:-0.7}
      - COGNEE_SEARCH_TYPES=VECTOR,GRAPH,INSIGHTS,GRAPH_COMPLETION

    volumes:
      - cognee_data:/app/data
      - cognee_models:/app/models
    networks:
      - superagent-network
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      chromadb:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 1G
    profiles:
      - default
      - ai
      - full

  # ChromaDB for Vector Storage
  chromadb:
    image: chromadb/chroma:0.6.3
    container_name: superagent-chromadb
    environment:
      - IS_PERSISTENT=TRUE
      - CHROMA_SERVER_AUTH_CREDENTIALS=${VECTOR_DB_KEY:-cognee_vector_key}
      - CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER=chromadb.auth.token.TokenConfigServerAuthCredentialsProvider
      - CHROMA_SERVER_AUTH_TOKEN_TRANSPORT_HEADER=AUTHORIZATION
      - CHROMA_SERVER_AUTH_PROVIDER=chromadb.auth.token.TokenAuthServerProvider
    volumes:
      - chromadb_data:/chroma/chroma/
    networks:
      - superagent-network
    ports:
      - "8001:8000"
    restart: unless-stopped
    profiles:
      - default
      - ai
      - full

  # Neo4j Graph Database (optional, for advanced graph features)
  neo4j:
    image: neo4j:latest
    container_name: superagent-neo4j
    environment:
      - NEO4J_AUTH=neo4j/cognee123
      - NEO4J_PLUGINS=["apoc", "graph-data-science"]
    ports:
      - "7474:7474"
      - "7687:7687"
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    networks:
      - superagent-network
    restart: unless-stopped
    profiles:
      - graph
      - full

  # Memgraph - High-performance in-memory graph database (alternative to Neo4j)
  memgraph:
    image: memgraph/memgraph-mage:latest
    container_name: superagent-memgraph
    ports:
      - "7688:7687"  # Bolt protocol
      - "7445:7444"  # Lab UI
    environment:
      - MEMGRAPH_USER=memgraph
      - MEMGRAPH_PASSWORD=cognee123
    volumes:
      - memgraph_data:/var/lib/memgraph
      - memgraph_logs:/var/log/memgraph
    networks:
      - superagent-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 512M
    profiles:
      - graph
      - full

  # Mock LLM Server for Testing
  mock-llm:
    build:
      context: ./tests/mock-llm-server
      dockerfile: Dockerfile
    container_name: superagent-mock-llm
    ports:
      - "${MOCK_LLM_PORT:-8090}:8090"
    environment:
      - PORT=8090
      - RESPONSE_DELAY=${MOCK_LLM_DELAY:-100}
    networks:
      - superagent-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8090/health"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped
    profiles:
      - testing
      - full

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  ollama_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  cognee_data:
    driver: local
  cognee_models:
    driver: local
  chromadb_data:
    driver: local
  neo4j_data:
    driver: local
  neo4j_logs:
    driver: local
  memgraph_data:
    driver: local
  memgraph_logs:
    driver: local

networks:
  superagent-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
